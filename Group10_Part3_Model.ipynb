{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Students:\n",
    "\n",
    "Joana Rodrigues - 20240603    \n",
    "Maria Francisca - 20240346     \n",
    "Rui Reis - 20240854      \n",
    "Tomás Silva - 20230982     \n",
    "Victor Pita - 20240596        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Part 3 - Model & Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Índice \n",
    "1. [Import the dataset](#introduction)   \n",
    "    1.1. [Import Materials](#importmaterials) \n",
    "2. [Data Exploration](#dataexploration)    \n",
    "3. [Preprocessing](#preprocessing)\n",
    "4. [Feature Selection](#featureselection)\n",
    "5. [Model](#model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Import Libraries\n",
    "For this project, many libraries need to be downloaded as they enable us to explore the dataset with more functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pickle\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler,LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LassoCV\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils.class_weight import compute_class_weight,  compute_sample_weight\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.cluster import DBSCAN\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "# pip install category_encoders\n",
    "import category_encoders as ce\n",
    "from imblearn.combine import SMOTEENN\n",
    "import hdbscan\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Import Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df= pd.read_csv('sample_submission.csv') \n",
    "df_train = pickle.load(open(\"df_train_cleaned.pkl\", 'rb'))\n",
    "df_test = pickle.load(open(\"df_test_cleaned.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "# df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3  Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_feature_types(df):\n",
    "    # Identifying date features\n",
    "    date_features = [column for column in df.columns if 'Date' in column]\n",
    "    \n",
    "    # Identifying categorical (object) features initially\n",
    "    categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    # Identifying boolean features\n",
    "    boolean_features = df.select_dtypes(include=['bool']).columns.tolist()\n",
    "    \n",
    "    # Identifying numerical features (integers and floats), but excluding those with 'Code', 'County', or 'Carrier' in their name\n",
    "    numerical_features = [\n",
    "        column for column in df.select_dtypes(include=['int64', 'float64']).columns\n",
    "        if 'Code' not in column and 'County' not in column and 'Carrier' not in column and 'Decision' not in column and 'Indicator' not in column and 'Grouped' not in column\n",
    "    ]\n",
    "    \n",
    "    # Adding features with 'Code', 'County', or 'Carrier' in the name to categorical features, even if they are numerical\n",
    "    categorical_features.extend([\n",
    "        column for column in df.columns if 'Code' in column or 'County' in column or 'Carrier' in column or 'Decision' in column or 'Grouped' in column\n",
    "    ])\n",
    "\n",
    "    # Removing duplicates in case any feature is accidentally added twice\n",
    "    categorical_features = list(set(categorical_features))\n",
    "    \n",
    "    return {\n",
    "        'date_features': date_features,\n",
    "        'numerical_features': numerical_features,\n",
    "        'categorical_features': categorical_features,\n",
    "        'boolean_features': boolean_features\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Split test and train\n",
    "Before the split, there is a separation of the target variable and others and there is an encoding of the target.        \n",
    "Labelencoder is used in this case as the 'Claim Injury Type' can be considered ordinal because there are injury types worse than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = df_train.drop(['Claim Injury Type'], axis=1)  # Drop target column to get features\n",
    "y = df_train['Claim Injury Type']  # Define target variable\n",
    "\n",
    "# Placeholder for the test set features\n",
    "X_final_test = df_test \n",
    "\n",
    "# Encode target variable\n",
    "target_le = LabelEncoder()\n",
    "target_le.fit(y)\n",
    "y = target_le.transform(y)  # Transform target variable into encoded form\n",
    "\n",
    "# Split data into train and test sets (with stratification for balanced classes)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treatment of the rest of the missing values    \n",
    "The treatment is done after the split to avoid data leakage, as the median of the whole df_train is different from the median in X_train and X_test should be seen as data to test the model, to validate it, rather than to train it.\n",
    "For the numerical columns it replaces them with the median due to not having removed the outliers, this value seems a better approach    \n",
    "For the categorical columns we substitute the missing values with the mode. Initially, we thought about substituting the missing values of the categoricals according to the mode for each type of injury but as there are not a lot of missing values in this stage, we went for a simpler approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_types = identify_feature_types(X_train)\n",
    "    \n",
    "    # For numerical columns: fill NaN with the median value (to avoid outlier influence)\n",
    "numerical_features = feature_types['numerical_features']\n",
    "for column in numerical_features:\n",
    "    if column in X_train.columns:\n",
    "        # Use the median value of the training set for filling missing values\n",
    "        median_value = X_train[column].median()  # Using median to handle potential outliers\n",
    "        X[column] = X[column].fillna(median_value)  # Impute in the original X dataset\n",
    "        X_train[column] = X_train[column].fillna(median_value)  # Impute in X_train\n",
    "        X_test[column] = X_test[column].fillna(median_value)  # Impute in X_test\n",
    "        X_final_test[column] = X_final_test[column].fillna(median_value)  # Impute in X_final_test\n",
    "\n",
    "    # For categorical columns: fill NaN with the mode (most frequent value)\n",
    "categorical_features = feature_types['categorical_features']\n",
    "    \n",
    "\n",
    "for column in categorical_features:\n",
    "    if column in X_train.columns:\n",
    "        # Use the mode value of the training set for filling missing values\n",
    "        mode_value = X_train[column].mode()[0]  # Find the mode (most frequent value) for each categorical column\n",
    "        X[column] = X[column].fillna(mode_value)  # Impute in the original X dataset\n",
    "        X_train[column] = X_train[column].fillna(mode_value)  # Impute in X_train\n",
    "        X_test[column] = X_test[column].fillna(mode_value)  # Impute in X_test\n",
    "        X_final_test[column] = X_final_test[column].fillna(mode_value)  # Impute in X_final_test\n",
    "\n",
    "    # # Check for missing values after applying handle_missing_values function\n",
    "    # print(\"Columns with missing values in X_train:\")\n",
    "    # print(X_train.columns[X_train.isna().any()].tolist())  # Using .any() to check for any NaNs in each column\n",
    "    # print(\"Columns with missing values in X_test:\")\n",
    "    # print(X_test.columns[X_test.isna().any()].tolist())\n",
    "    # print(\"Columns with missing values in X_final_test:\")\n",
    "    # print(X_final_test.columns[X_final_test.isna().any()].tolist())   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that checks the data in each of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: Age at Injury\n",
      "Unique values: [29. 49. 46. 65. 25. 50. 42. 28. 34. 36. 21. 62. 57. 69. 20. 19. 63. 59.\n",
      " 56. 22. 37. 54. 53. 64. 27. 48. 61. 39. 51. 52. 35. 38. 30. 67. 26. 41.\n",
      " 58. 55. 23. 31. 40. 47. 24. 66. 32. 33. 73. 45. 60. 43. 44. 16. 18. 17.\n",
      " 68. 77. 71. 70. 75. 74. 83. 72. 76. 15. 78. 79. 82. 80. 81. 84. 85. 14.]\n",
      "--------------------------------------------------\n",
      "Column: Alternative Dispute Resolution\n",
      "Unique values: ['N' 'Y' 'U']\n",
      "--------------------------------------------------\n",
      "Column: Attorney/Representative\n",
      "Unique values: [0 1]\n",
      "--------------------------------------------------\n",
      "Column: Carrier Name\n",
      "Unique values: ['TRI-STATE INS CO OF MINNESOTA' 'YONKERS, CITY OF' 'STATE INSURANCE FUND'\n",
      " ... 'ENTERGY NUCLEAR OPERATIONS, IN' 'SCHENEVUS CENTRAL SCH DIST'\n",
      " 'PEERLESS INDEMNITY INS CO']\n",
      "--------------------------------------------------\n",
      "Column: Carrier Type\n",
      "Unique values: ['1A. PRIVATE' '3A. SELF PUBLIC' '2A. SIF' '4A. SELF PRIVATE' 'UNKNOWN'\n",
      " '5D. SPECIAL FUND - UNKNOWN' '5C. SPECIAL FUND - POI CARRIER WCB MENANDS'\n",
      " '5A. SPECIAL FUND - CONS. COMM. (SECT. 25-A)']\n",
      "--------------------------------------------------\n",
      "Column: County of Injury\n",
      "Unique values: ['ROCKLAND' 'WESTCHESTER' 'HERKIMER' 'MONROE' 'SUFFOLK' 'ORANGE' 'KINGS'\n",
      " 'BRONX' 'ONTARIO' 'NEW YORK' 'DUTCHESS' 'WARREN' 'BROOME' 'CHEMUNG'\n",
      " 'CLINTON' 'ERIE' 'NASSAU' 'GENESEE' 'RICHMOND' 'PUTNAM' 'QUEENS'\n",
      " 'NIAGARA' 'RENSSELAER' 'WASHINGTON' 'ALBANY' 'CHAUTAUQUA' 'ONONDAGA'\n",
      " 'FULTON' 'SARATOGA' 'COLUMBIA' 'CAYUGA' 'TOMPKINS' 'ULSTER' 'DELAWARE'\n",
      " 'CATTARAUGUS' 'ONEIDA' 'SULLIVAN' 'MADISON' 'FRANKLIN' 'OSWEGO' 'WAYNE'\n",
      " 'TIOGA' 'STEUBEN' 'SCHUYLER' 'SCHENECTADY' 'JEFFERSON' 'CHENANGO' 'LEWIS'\n",
      " 'LIVINGSTON' 'GREENE' 'ST. LAWRENCE' 'MONTGOMERY' 'SENECA' 'ORLEANS'\n",
      " 'YATES' 'WYOMING' 'HAMILTON' 'ALLEGANY' 'SCHOHARIE' 'UNKNOWN' 'CORTLAND'\n",
      " 'ESSEX' 'OTSEGO']\n",
      "--------------------------------------------------\n",
      "Column: COVID-19 Indicator\n",
      "Unique values: [0 1]\n",
      "--------------------------------------------------\n",
      "Column: District Name\n",
      "Unique values: ['NYC' 'SYRACUSE' 'ROCHESTER' 'HAUPPAUGE' 'ALBANY' 'BINGHAMTON' 'BUFFALO'\n",
      " 'STATEWIDE']\n",
      "--------------------------------------------------\n",
      "Column: Gender\n",
      "Unique values: ['M' 'F' 'U' 'X']\n",
      "--------------------------------------------------\n",
      "Column: Industry Code\n",
      "Unique values: [71. 92. 72. 62. 51. 23. 81. 44. 11. 48. 61. 53. 42. 54. 56. 45. 49. 33.\n",
      " 31. 32. 52. 22. 21. 55.]\n",
      "--------------------------------------------------\n",
      "Column: Medical Fee Region\n",
      "Unique values: ['III' 'UK' 'I' 'II' 'IV']\n",
      "--------------------------------------------------\n",
      "Column: WCIO Cause of Injury Code\n",
      "Unique values: [74. 33. 97. 31. 85. 25. 76. 75. 56. 45. 83. 68. 57. 19. 81. 79. 50.  1.\n",
      " 26. 32. 29. 17. 77. 27. 53. 99. 16. 60. 15. 70. 59. 13. 18. 20. 54.  2.\n",
      " 82. 66. 12.  5. 84. 98. 55. 89.  6. 58. 41. 87.  3. 10. 30. 88. 48. 80.\n",
      "  9. 90. 69. 78.  4. 28. 46. 94. 61. 67. 65. 52. 95. 11. 93. 96. 86.  7.\n",
      "  8. 14. 40. 91. 47.]\n",
      "--------------------------------------------------\n",
      "Column: WCIO Nature of Injury Code\n",
      "Unique values: [52. 90. 10. 37. 16. 40. 34. 49. 83. 25.  7. 43. 59. 28. 13. 80.  4. 78.\n",
      " 36. 53.  1. 19. 73. 65. 69. 77. 32. 31. 38. 46. 55. 42.  2. 61. 72. 71.\n",
      " 68. 74. 58. 41.  3. 64. 47. 66. 91. 60. 30. 75. 67. 54. 70. 63. 79. 76.\n",
      " 22. 62.]\n",
      "--------------------------------------------------\n",
      "Column: WCIO Part Of Body Code\n",
      "Unique values: [53. -9. 32. 36. 38. 63. 55. 11. 10. 61. 66. 42. 18. 35. 56. 14. 19. 33.\n",
      " 54. 43. 90. 45. 17. 41. 58. 25. 34. 52. 51. 99. 65. 37. 31. 15. 91. 60.\n",
      " 39. 30. 48. 44. 13. 21. 57. 50. 40. 12. 22. 20. 16. 62. 47. 49. 23. 46.\n",
      " 24. 64. 26.]\n",
      "--------------------------------------------------\n",
      "Column: Zip Code\n",
      "Unique values: ['10962' '08520' '13413' ... '70778' '02673' '36832']\n",
      "--------------------------------------------------\n",
      "Column: Agreement Reached\n",
      "Unique values: <BooleanArray>\n",
      "[False, True]\n",
      "Length: 2, dtype: boolean\n",
      "--------------------------------------------------\n",
      "Column: Number of Dependents\n",
      "Unique values: [0. 4. 5. 6. 3. 2. 1.]\n",
      "--------------------------------------------------\n",
      "Column: Industry Grouped\n",
      "Unique values: ['Leisure & Hospitality' 'Public Administration & Professional Services'\n",
      " 'Healthcare & Social Services' 'Education & Information'\n",
      " 'Construction & Manufacturing' 'Other Services' 'Trade & Commerce'\n",
      " 'Natural Resources' 'Transportation & Infrastructure'\n",
      " 'Finance & Real Estate' 'Corporate Services']\n",
      "--------------------------------------------------\n",
      "Column: WCIO Cause of Injury Grouped\n",
      "Unique values: ['Physical Impact Injuries' 'Repetitive Strain Injuries'\n",
      " 'Other / Miscellaneous Causes' 'Machinery or Tool-Related Injuries'\n",
      " 'Environmental/Exposure Injuries' 'Vehicle-Related Injuries']\n",
      "--------------------------------------------------\n",
      "Column: WCIO Nature of Injury Grouped\n",
      "Unique values: ['Soft Tissue & Strains' 'Multiple and Complex Injuries'\n",
      " 'Fractures & Bone Injuries' 'Trauma and Physical Injuries' 'Diseases'\n",
      " 'Mental & Psychological Injuries' 'Other'\n",
      " 'Exposure and Environmental Injuries']\n",
      "--------------------------------------------------\n",
      "Column: WCIO Part of Body Grouped\n",
      "Unique values: ['Lower Body' 'Multiple Body Parts' 'Upper Body' 'Head and Neck'\n",
      " 'Other / Unclassified' 'Spinal Cord & Vertebrae' 'Pelvis Area'\n",
      " 'Internal Organs']\n",
      "--------------------------------------------------\n",
      "Column: log Average Weekly Wage\n",
      "Unique values: [0.         7.80850589 6.92362863 ... 5.7881849  7.18073226 8.22884423]\n",
      "--------------------------------------------------\n",
      "Column: C-2 Date Binary\n",
      "Unique values: [ True False]\n",
      "--------------------------------------------------\n",
      "Column: Log C-2 Days\n",
      "Unique values: [1.09861229 1.60943791 0.         ... 9.59940506 8.71193727 9.19238005]\n",
      "--------------------------------------------------\n",
      "Column: C-3 Date Binary\n",
      "Unique values: [False  True]\n",
      "--------------------------------------------------\n",
      "Column: Log C-3 Days\n",
      "Unique values: [0.         5.420535   4.62497281 ... 7.20637729 8.94376726 7.60190196]\n",
      "--------------------------------------------------\n",
      "Column: First Hearing Date Binary\n",
      "Unique values: [False  True]\n",
      "--------------------------------------------------\n",
      "Column: Log First Hearing Days\n",
      "Unique values: [0.         5.74939299 4.8978398  ... 9.08239336 8.58988588 7.19443685]\n",
      "--------------------------------------------------\n",
      "Column: Log Assembly Days\n",
      "Unique values: [1.09861229 1.60943791 0.         ... 6.88346259 8.71193727 9.19238005]\n",
      "--------------------------------------------------\n",
      "Column: Day of Week\n",
      "Unique values: [2. 3. 1. 0. 6. 5. 4.]\n",
      "--------------------------------------------------\n",
      "Column: Day of Month\n",
      "Unique values: [10.  8.  7. 31. 29. 27. 14. 30.  4. 21. 16.  6. 17. 22. 11. 24. 15.  2.\n",
      " 19. 20. 18. 25. 23. 13. 28.  5. 12.  1.  9.  3. 26.]\n",
      "--------------------------------------------------\n",
      "Column: Month\n",
      "Unique values: [ 6. 12.  9.  5.  8.  7. 10.  2.  4.  3. 11.  1.]\n",
      "--------------------------------------------------\n",
      "Column: Year\n",
      "Unique values: [2020. 2022. 2021. 2019. 2018. 2015. 1995. 2007. 2016. 2017. 2003. 2001.\n",
      " 1992. 1988. 2011. 2012. 2013. 2000. 1999. 2005. 2014. 2010. 2009. 2004.\n",
      " 1996. 2006. 2023. 1997. 1991. 2008. 1978. 1998. 1982. 2002. 1994. 1990.\n",
      " 1981. 1984. 1977. 1993. 1989. 1972. 1961. 1987. 1985. 1983. 1973. 1980.\n",
      " 1979. 1975. 1976. 1971. 1974. 1986. 1966. 1967.]\n",
      "--------------------------------------------------\n",
      "Column: IME-4 Count Binary nan\n",
      "Unique values: [1 0]\n",
      "--------------------------------------------------\n",
      "Column: Age at Injury\n",
      "Unique values: [26. 29. 51. 56. 53. 82. 59. 52. 24. 81. 21. 61. 68. 43. 62. 47. 55. 23.\n",
      " 49. 44. 37. 54. 41. 30. 28. 25. 50. 45. 63. 27. 31. 46. 58. 60. 34. 65.\n",
      " 39. 40. 32. 48. 75. 57. 20. 36. 64. 38. 70. 83. 33. 66. 42. 35. 22. 19.\n",
      " 67. 17. 77. 18. 74. 79. 76. 72. 69. 73. 16. 71. 80. 14. 78. 85. 15. 84.]\n",
      "--------------------------------------------------\n",
      "Column: Alternative Dispute Resolution\n",
      "Unique values: ['N' 'Y' 'U']\n",
      "--------------------------------------------------\n",
      "Column: Attorney/Representative\n",
      "Unique values: [0 1]\n",
      "--------------------------------------------------\n",
      "Column: Carrier Name\n",
      "Unique values: ['SAFETY NATIONAL CASUALTY CORP' 'ARCH INDEMNITY INSURANCE CO.'\n",
      " 'POLICE, FIRE, SANITATION' ... 'NORWOOD-NORFOLK CSD'\n",
      " 'ROSCOE CENTRAL SCHOOL DISTRICT' 'THE TRAVELERS CASUALTY COMPANY']\n",
      "--------------------------------------------------\n",
      "Column: Carrier Type\n",
      "Unique values: ['1A. PRIVATE' '3A. SELF PUBLIC' '2A. SIF' 'UNKNOWN' '4A. SELF PRIVATE'\n",
      " '5D. SPECIAL FUND - UNKNOWN']\n",
      "--------------------------------------------------\n",
      "Column: County of Injury\n",
      "Unique values: ['DUTCHESS' 'RICHMOND' 'BRONX' 'NASSAU' 'SUFFOLK' 'CHAUTAUQUA' 'KINGS'\n",
      " 'OTSEGO' 'ERIE' 'OSWEGO' 'YATES' 'SARATOGA' 'WESTCHESTER' 'QUEENS'\n",
      " 'ALBANY' 'ONONDAGA' 'MONROE' 'RENSSELAER' 'ORANGE' 'CLINTON' 'PUTNAM'\n",
      " 'HERKIMER' 'FRANKLIN' 'NEW YORK' 'COLUMBIA' 'CAYUGA' 'NIAGARA' 'CORTLAND'\n",
      " 'ROCKLAND' 'MADISON' 'TIOGA' 'ONTARIO' 'SULLIVAN' 'TOMPKINS' 'CHEMUNG'\n",
      " 'ONEIDA' 'FULTON' 'WASHINGTON' 'HAMILTON' 'LIVINGSTON' 'UNKNOWN'\n",
      " 'STEUBEN' 'BROOME' 'ESSEX' 'JEFFERSON' 'WAYNE' 'ULSTER' 'ST. LAWRENCE'\n",
      " 'SCHUYLER' 'ALLEGANY' 'SCHENECTADY' 'WYOMING' 'CATTARAUGUS' 'GENESEE'\n",
      " 'SENECA' 'WARREN' 'ORLEANS' 'SCHOHARIE' 'CHENANGO' 'LEWIS' 'GREENE'\n",
      " 'DELAWARE' 'MONTGOMERY']\n",
      "--------------------------------------------------\n",
      "Column: COVID-19 Indicator\n",
      "Unique values: [0 1]\n",
      "--------------------------------------------------\n",
      "Column: District Name\n",
      "Unique values: ['ALBANY' 'NYC' 'HAUPPAUGE' 'BUFFALO' 'BINGHAMTON' 'SYRACUSE' 'ROCHESTER'\n",
      " 'STATEWIDE']\n",
      "--------------------------------------------------\n",
      "Column: Gender\n",
      "Unique values: ['M' 'F' 'U' 'X']\n",
      "--------------------------------------------------\n",
      "Column: Industry Code\n",
      "Unique values: [44. 62. 92. 61. 23. 56. 48. 51. 33. 71. 53. 72. 42. 11. 81. 55. 54. 22.\n",
      " 49. 32. 45. 52. 21. 31.]\n",
      "--------------------------------------------------\n",
      "Column: Medical Fee Region\n",
      "Unique values: ['II' 'IV' 'I' 'UK' 'III']\n",
      "--------------------------------------------------\n",
      "Column: WCIO Cause of Injury Code\n",
      "Unique values: [32. 74. 57. 85. 26. 29. 31. 90. 12. 56. 99. 98. 75. 13. 81. 79. 60. 65.\n",
      " 83. 15. 16. 17. 33. 97. 45. 68. 27. 58. 25. 52. 53. 78. 70. 89.  1. 87.\n",
      " 19. 76. 30. 66. 18. 10.  5. 82.  2. 50.  6. 54. 77. 55. 46.  9. 61. 67.\n",
      " 20. 80. 28. 59. 69. 88. 48. 84. 95.  3. 11. 47. 94.  4. 40. 96. 86. 91.\n",
      " 14. 41.  7. 93.  8.]\n",
      "--------------------------------------------------\n",
      "Column: WCIO Nature of Injury Code\n",
      "Unique values: [52. 59. 10. 49. 28. 77. 65. 40. 16. 90. 83.  1. 37. 78. 71. 53. 43. 25.\n",
      "  4. 31. 73. 34. 80.  7. 36.  3. 72. 42.  2. 68. 61. 13. 91. 41. 55. 19.\n",
      " 69. 47. 46. 32. 66. 60. 58. 54. 38. 74. 75. 30. 64. 67. 22. 79. 70.]\n",
      "--------------------------------------------------\n",
      "Column: WCIO Part Of Body Code\n",
      "Unique values: [56. -9. 55. 42. 44. 90. 91. 36. 46. 60. 38. 18. 40. 32. 12. 50. 33. 48.\n",
      " 11. 37. 35. 31. 53. 61. 66. 34. 13. 41. 14. 54. 25. 10. 24. 52. 51. 57.\n",
      " 63. 58. 99. 20. 39. 45. 15. 49. 30. 16. 65. 19. 62. 21. 43. 17. 22. 47.\n",
      " 64. 23. 26.]\n",
      "--------------------------------------------------\n",
      "Column: Zip Code\n",
      "Unique values: ['12603' '10312' '10463' ... 14537.0 '18615' '34224']\n",
      "--------------------------------------------------\n",
      "Column: Agreement Reached\n",
      "Unique values: <BooleanArray>\n",
      "[False, True]\n",
      "Length: 2, dtype: boolean\n",
      "--------------------------------------------------\n",
      "Column: Number of Dependents\n",
      "Unique values: [0. 5. 6. 1. 4. 2. 3.]\n",
      "--------------------------------------------------\n",
      "Column: Industry Grouped\n",
      "Unique values: ['Trade & Commerce' 'Healthcare & Social Services'\n",
      " 'Public Administration & Professional Services' 'Education & Information'\n",
      " 'Construction & Manufacturing' 'Transportation & Infrastructure'\n",
      " 'Leisure & Hospitality' 'Finance & Real Estate' 'Natural Resources'\n",
      " 'Other Services' 'Corporate Services']\n",
      "--------------------------------------------------\n",
      "Column: WCIO Cause of Injury Grouped\n",
      "Unique values: ['Environmental/Exposure Injuries' 'Physical Impact Injuries'\n",
      " 'Repetitive Strain Injuries' 'Other / Miscellaneous Causes'\n",
      " 'Machinery or Tool-Related Injuries' 'Vehicle-Related Injuries']\n",
      "--------------------------------------------------\n",
      "Column: WCIO Nature of Injury Grouped\n",
      "Unique values: ['Soft Tissue & Strains' 'Fractures & Bone Injuries'\n",
      " 'Mental & Psychological Injuries' 'Diseases'\n",
      " 'Multiple and Complex Injuries' 'Trauma and Physical Injuries'\n",
      " 'Exposure and Environmental Injuries' 'Other']\n",
      "--------------------------------------------------\n",
      "Column: WCIO Part of Body Grouped\n",
      "Unique values: ['Lower Body' 'Multiple Body Parts' 'Upper Body' 'Pelvis Area'\n",
      " 'Internal Organs' 'Other / Unclassified' 'Head and Neck'\n",
      " 'Spinal Cord & Vertebrae']\n",
      "--------------------------------------------------\n",
      "Column: log Average Weekly Wage\n",
      "Unique values: [5.62491963 0.         7.48773376 ... 6.41781013 7.38703451 7.08043046]\n",
      "--------------------------------------------------\n",
      "Column: C-2 Date Binary\n",
      "Unique values: [ True False]\n",
      "--------------------------------------------------\n",
      "Column: Log C-2 Days\n",
      "Unique values: [1.79175947 1.94591015 5.0689042  ... 7.79110951 7.87815534 7.28000825]\n",
      "--------------------------------------------------\n",
      "Column: C-3 Date Binary\n",
      "Unique values: [False  True]\n",
      "--------------------------------------------------\n",
      "Column: Log C-3 Days\n",
      "Unique values: [0.         2.89037176 2.83321334 ... 6.98286275 7.28550655 8.32360844]\n",
      "--------------------------------------------------\n",
      "Column: First Hearing Date Binary\n",
      "Unique values: [False  True]\n",
      "--------------------------------------------------\n",
      "Column: Log First Hearing Days\n",
      "Unique values: [0.         5.27299956 4.78749174 ... 7.43955931 7.34923082 8.32965807]\n",
      "--------------------------------------------------\n",
      "Column: Log Assembly Days\n",
      "Unique values: [2.07944154 1.94591015 3.09104245 ... 7.87815534 7.28000825 6.50727771]\n",
      "--------------------------------------------------\n",
      "Column: Day of Week\n",
      "Unique values: [0. 1. 2. 4. 5. 3. 6.]\n",
      "--------------------------------------------------\n",
      "Column: Day of Month\n",
      "Unique values: [23.  5. 17. 25.  4. 10. 21.  9. 24. 29. 31. 13. 14. 19. 28. 30. 20.  3.\n",
      "  1.  8. 16.  2. 11. 26. 27. 15. 18. 22. 12.  7.  6.]\n",
      "--------------------------------------------------\n",
      "Column: Month\n",
      "Unique values: [ 8.  7.  5. 11.  6. 10.  1. 12.  9.  3.  2.  4.]\n",
      "--------------------------------------------------\n",
      "Column: Year\n",
      "Unique values: [2021. 2022. 2020. 2019. 2002. 2009. 2005. 2007. 2015. 1995. 2013. 2017.\n",
      " 2012. 1994. 2008. 1977. 2018. 2001. 1998. 1988. 2004. 1992. 2003. 2014.\n",
      " 2016. 2010. 2011. 1997. 2023. 1991. 2000. 1999. 1987. 1983. 1973. 2006.\n",
      " 1996. 1966. 1990. 1969. 1986. 1967. 1989. 1984. 1981. 1971. 1993. 1974.\n",
      " 1975. 1963. 1985.]\n",
      "--------------------------------------------------\n",
      "Column: IME-4 Count Binary nan\n",
      "Unique values: [1 0]\n",
      "--------------------------------------------------\n",
      "Column: Age at Injury\n",
      "Unique values: [ 19  59  55  25  36  43  40  48  51  57  67  39  56  42  66  31  32  34\n",
      "  53  54  23  52  22  41  20  75  47  28  30  45  29  18  71  60  46  27\n",
      "  64  65  37  50  62  58  33  24  35  38  21  49  70  61  44  26  63  74\n",
      "   0  72  68  89  17  16  85  69  73  80  76  98  79  81  78  83  77  15\n",
      "  82  88  84  14  86  87  97  11  10  93 113  12  90 100 104  96  95  94\n",
      "   8  91  13   6  99  92   9 101 105 114   7   5]\n",
      "--------------------------------------------------\n",
      "Column: Alternative Dispute Resolution\n",
      "Unique values: ['N' 'Y' 'U']\n",
      "--------------------------------------------------\n",
      "Column: Attorney/Representative\n",
      "Unique values: [0 1]\n",
      "--------------------------------------------------\n",
      "Column: Carrier Name\n",
      "Unique values: ['INDEMNITY INSURANCE CO OF' 'A I U INSURANCE COMPANY'\n",
      " 'AMGUARD INSURANCE COMPANY' ... 'GATES VOLUNTEER AMBULANCE SVC'\n",
      " 'CHENANGO CNTY. SELF-INS PLAN' 'VILLAGE OF HOMER']\n",
      "--------------------------------------------------\n",
      "Column: Carrier Type\n",
      "Unique values: ['1A. PRIVATE' '3A. SELF PUBLIC' '4A. SELF PRIVATE' '2A. SIF' 'UNKNOWN'\n",
      " '5D. SPECIAL FUND - UNKNOWN'\n",
      " '5A. SPECIAL FUND - CONS. COMM. (SECT. 25-A)']\n",
      "--------------------------------------------------\n",
      "Column: County of Injury\n",
      "Unique values: ['BRONX' 'QUEENS' 'WESTCHESTER' 'KINGS' 'ORANGE' 'NIAGARA' 'HERKIMER'\n",
      " 'CHAUTAUQUA' 'CHEMUNG' 'DUTCHESS' 'CLINTON' 'SUFFOLK' 'ERIE' 'RENSSELAER'\n",
      " 'MONROE' 'NASSAU' 'ONTARIO' 'JEFFERSON' 'WASHINGTON' 'NEW YORK' 'OSWEGO'\n",
      " 'COLUMBIA' 'ROCKLAND' 'ONEIDA' 'DELAWARE' 'SCHENECTADY' 'SCHOHARIE'\n",
      " 'SARATOGA' 'FRANKLIN' 'ST. LAWRENCE' 'GENESEE' 'CAYUGA' 'CHENANGO'\n",
      " 'WARREN' 'ALLEGANY' 'ALBANY' 'ONONDAGA' 'GREENE' 'ORLEANS' 'SCHUYLER'\n",
      " 'BROOME' 'ULSTER' 'SULLIVAN' 'RICHMOND' 'STEUBEN' 'FULTON' 'PUTNAM'\n",
      " 'LEWIS' 'CORTLAND' 'MADISON' 'OTSEGO' 'SENECA' 'ESSEX' 'LIVINGSTON'\n",
      " 'WYOMING' 'YATES' 'TIOGA' 'TOMPKINS' 'UNKNOWN' 'CATTARAUGUS' 'MONTGOMERY'\n",
      " 'WAYNE' 'HAMILTON']\n",
      "--------------------------------------------------\n",
      "Column: COVID-19 Indicator\n",
      "Unique values: [0 1]\n",
      "--------------------------------------------------\n",
      "Column: District Name\n",
      "Unique values: ['NYC' 'ALBANY' 'BUFFALO' 'SYRACUSE' 'BINGHAMTON' 'HAUPPAUGE' 'ROCHESTER'\n",
      " 'STATEWIDE']\n",
      "--------------------------------------------------\n",
      "Column: Gender\n",
      "Unique values: ['M' 'F' 'U' 'X']\n",
      "--------------------------------------------------\n",
      "Column: Industry Code\n",
      "Unique values: [48. 45. 56. 55. 72. 32. 44. 53. 92. 52. 61. 22. 33. 71. 81. 31. 62. 23.\n",
      " 54. 42. 51. 11. 49. 21.]\n",
      "--------------------------------------------------\n",
      "Column: Medical Fee Region\n",
      "Unique values: ['IV' 'III' 'I' 'II' 'UK']\n",
      "--------------------------------------------------\n",
      "Column: WCIO Cause of Injury Code\n",
      "Unique values: [31. 75. 68. 25. 79. 90. 56. 27. 87.  5. 53. 29. 16. 12. 26. 32. 85. 60.\n",
      " 74. 57. 99. 19. 18. 69. 15. 45. 81. 70. 83. 98. 33. 50. 55. 97. 54. 46.\n",
      " 76. 66. 89. 10. 80. 77. 28. 30.  1. 13. 58. 17. 93.  3. 78. 82. 88.  2.\n",
      " 52. 59.  9. 61. 48. 86. 20. 94. 65. 84.  6. 96. 95. 41. 67. 91.  4. 14.\n",
      " 11.  7. 47. 40.  8.]\n",
      "--------------------------------------------------\n",
      "Column: WCIO Nature of Injury Code\n",
      "Unique values: [10. 49. 40. 77. 25.  4. 52. 28.  7. 43. 16. 90. 59.  1. 83. 34. 80. 13.\n",
      " 78. 31.  2. 68. 37. 30. 42. 53. 65. 55. 73. 72. 36. 66. 46. 47. 58. 41.\n",
      " 38. 19.  3. 69. 71. 32. 22. 91. 74. 67. 60. 70. 54. 62. 61. 64. 79. 75.\n",
      " 76. 63.]\n",
      "--------------------------------------------------\n",
      "Column: WCIO Part Of Body Code\n",
      "Unique values: [54. 10. 62. 53. 37. 66. 38. 14. 31. 42. -9. 34. 36. 32. 61. 18. 33. 55.\n",
      " 35. 48. 12. 41. 11. 44. 25. 56. 60. 52. 15. 43. 63. 51. 91. 19. 13. 46.\n",
      " 58. 49. 65. 57. 39. 17. 21. 16. 23. 20. 26. 22. 47. 24. 45. 99. 64. 30.]\n",
      "--------------------------------------------------\n",
      "Column: Zip Code\n",
      "Unique values: ['10466' '11691' '10604' ... '33179' '30152' '33081']\n",
      "--------------------------------------------------\n",
      "Column: Number of Dependents\n",
      "Unique values: [1 0 6 5 4 3 2]\n",
      "--------------------------------------------------\n",
      "Column: Industry Grouped\n",
      "Unique values: ['Transportation & Infrastructure' 'Trade & Commerce'\n",
      " 'Public Administration & Professional Services' 'Corporate Services'\n",
      " 'Leisure & Hospitality' 'Finance & Real Estate' 'Education & Information'\n",
      " 'Other Services' 'Healthcare & Social Services'\n",
      " 'Construction & Manufacturing' 'Natural Resources']\n",
      "--------------------------------------------------\n",
      "Column: WCIO Cause of Injury Grouped\n",
      "Unique values: ['Physical Impact Injuries' 'Repetitive Strain Injuries'\n",
      " 'Environmental/Exposure Injuries' 'Other / Miscellaneous Causes'\n",
      " 'Machinery or Tool-Related Injuries' 'Vehicle-Related Injuries']\n",
      "--------------------------------------------------\n",
      "Column: WCIO Nature of Injury Grouped\n",
      "Unique values: ['Soft Tissue & Strains' 'Mental & Psychological Injuries'\n",
      " 'Fractures & Bone Injuries' 'Multiple and Complex Injuries' 'Diseases'\n",
      " 'Trauma and Physical Injuries' 'Exposure and Environmental Injuries'\n",
      " 'Other']\n",
      "--------------------------------------------------\n",
      "Column: WCIO Part of Body Grouped\n",
      "Unique values: ['Lower Body' 'Head and Neck' 'Other / Unclassified' 'Upper Body'\n",
      " 'Multiple Body Parts' 'Internal Organs' 'Spinal Cord & Vertebrae'\n",
      " 'Pelvis Area']\n",
      "--------------------------------------------------\n",
      "Column: log Average Weekly Wage\n",
      "Unique values: [0.         6.5355315  7.07474321 ... 7.39320155 7.02243127 7.21994214]\n",
      "--------------------------------------------------\n",
      "Column: C-2 Date Binary\n",
      "Unique values: [ True False]\n",
      "--------------------------------------------------\n",
      "Column: Log C-2 Days\n",
      "Unique values: [2.30258509 3.78418963 1.79175947 ... 6.74641213 7.42773884 7.57558465]\n",
      "--------------------------------------------------\n",
      "Column: C-3 Date Binary\n",
      "Unique values: [False  True]\n",
      "--------------------------------------------------\n",
      "Column: Log C-3 Days\n",
      "Unique values: [0.         4.24849524 6.10255859 ... 7.05185562 6.81234509 7.49665244]\n",
      "--------------------------------------------------\n",
      "Column: First Hearing Date Binary\n",
      "Unique values: [False  True]\n",
      "--------------------------------------------------\n",
      "Column: Log First Hearing Days\n",
      "Unique values: [0.         5.52942909 3.91202301 ... 7.15617664 6.44730586 8.1693364 ]\n",
      "--------------------------------------------------\n",
      "Column: Log Assembly Days\n",
      "Unique values: [2.30258509 3.78418963 2.07944154 ... 7.49942329 8.78416222 8.36287583]\n",
      "--------------------------------------------------\n",
      "Column: Day of Week\n",
      "Unique values: [5. 6. 0. 2. 1. 3. 4.]\n",
      "--------------------------------------------------\n",
      "Column: Day of Month\n",
      "Unique values: [24. 20. 26. 28. 22. 13.  1. 19. 29.  9. 25. 31. 23. 30. 14. 10. 16. 27.\n",
      " 12.  3. 17. 21.  2.  7. 11.  4.  5. 15.  6. 18.  8.]\n",
      "--------------------------------------------------\n",
      "Column: Month\n",
      "Unique values: [12. 11.  9.  8.  1. 10.  4.  7.  6.  3.  5.  2.]\n",
      "--------------------------------------------------\n",
      "Column: Year\n",
      "Unique values: [2022. 2023. 2021. 2020. 2016. 2019. 2014. 2017. 2013. 1999. 2004. 1990.\n",
      " 1993. 1991. 1994. 2002. 2012. 1988. 2009. 2006. 2001. 2003. 2007. 2008.\n",
      " 2011. 2005. 2018. 2010. 1997. 1998. 1996. 2000. 1982. 1980. 2015. 1983.\n",
      " 1989. 1995. 1992. 1973. 2024. 1984. 1986. 1985. 1987. 1981. 1966. 1975.\n",
      " 1978. 1976. 1977. 1974.]\n",
      "--------------------------------------------------\n",
      "Column: IME-4 Count Binary nan\n",
      "Unique values: [1 0]\n",
      "--------------------------------------------------\n",
      "Column: Agreement Reached\n",
      "Unique values: [0 1]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Check for unexpected placeholder values before encoding and scaling\n",
    "def check_placeholders(df):\n",
    "    for col in df.columns:\n",
    "        unique_vals = df[col].unique()\n",
    "        print(f\"Column: {col}\")\n",
    "        print(f\"Unique values: {unique_vals}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Check columns in X, X_train, X_test, and X_final_test\n",
    "check_placeholders(X_train)\n",
    "check_placeholders(X_test)\n",
    "check_placeholders(X_final_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Categorical Enconding\n",
    "The encoder chosen was CountEncoder because it represents categorical values based on their frequency, providing a meaningful numerical encoding. Unlike other encoders that assign arbitrary numbers to categories, CountEncoder avoids the risk of introducing misleading patterns or biases into the model, which could potentially mislead the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_encode = [col for col in X_train.columns if X_train[col].dtype == 'object']\n",
    "\n",
    "# Initialize the encoder (CountEncoder in this case)\n",
    "encoder = ce.CountEncoder()\n",
    "\n",
    "encoder_dict = {}\n",
    "for col in columns_to_encode:\n",
    "    enc = encoder.fit(X_train[[col]])\n",
    "    encoder_dict[col] = copy.copy(enc)\n",
    "    X_train[col] = encoder.transform(X_train[[col]])\n",
    "    X_test[col] = encoder.transform(X_test[[col]]).fillna(0)  # Handle unseen categories in validation\n",
    "    X_final_test[col] = encoder.transform(X_final_test[[col]]).fillna(0)  # Handle unseen categories in test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Division of features\n",
    "This division is made because different feature selection methods are used for the different types of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numerical features based on df_train\n",
    "feature_types = identify_feature_types(X_train)\n",
    "\n",
    "metric_features = feature_types['numerical_features'] + feature_types['boolean_features']\n",
    "non_metric_features = feature_types['categorical_features'] \n",
    "\n",
    "# Separate into numerical and non-numerical features for training and testing\n",
    "feat_x_train_num = X_train[metric_features]\n",
    "feat_x_train_nnum = X_train[non_metric_features]\n",
    "\n",
    "feat_x_val_num = X_test[metric_features]\n",
    "feat_x_val_nnum = X_test[non_metric_features]\n",
    "\n",
    "# Optionally, for final testing, you can also separate features\n",
    "feat_x_final_test_num = X_final_test[metric_features]\n",
    "feat_x_final_test_nnum = X_final_test[non_metric_features]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Filter methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Cramers\n",
    "Chi-squared was also tried for categorical data but as it considered every feature relevant, even after the change of the alpha.\n",
    "This way, we decided to use cramers matrix, since it evaluates the strength of association between categorical variables, providing a clear understanding of their relationships. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cramers V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WCIO Cause of Injury Code</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>County of Injury</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WCIO Part Of Body Code</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WCIO Part of Body Grouped</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carrier Name</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carrier Type</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WCIO Nature of Injury Code</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Industry Grouped</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WCIO Cause of Injury Grouped</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zip Code</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WCIO Nature of Injury Grouped</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Industry Code</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Cramers V\n",
       "WCIO Cause of Injury Code           True\n",
       "County of Injury                    True\n",
       "WCIO Part Of Body Code              True\n",
       "WCIO Part of Body Grouped          False\n",
       "Carrier Name                       False\n",
       "Carrier Type                        True\n",
       "WCIO Nature of Injury Code          True\n",
       "Industry Grouped                   False\n",
       "WCIO Cause of Injury Grouped       False\n",
       "Zip Code                            True\n",
       "WCIO Nature of Injury Grouped      False\n",
       "Industry Code                       True"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty matrix for Cramér's V\n",
    "cramers_v_matrix = pd.DataFrame(index=feat_x_train_nnum.columns, \n",
    "                                columns=feat_x_train_nnum.columns, dtype=float)\n",
    "\n",
    "# Calculate Cramér's V for each pair of categorical features\n",
    "for i, feature1 in enumerate(feat_x_train_nnum.columns):\n",
    "    for feature2 in feat_x_train_nnum.columns[i:]:\n",
    "        contingency_table = pd.crosstab(feat_x_train_nnum[feature1], feat_x_train_nnum[feature2])\n",
    "        chi2, _, _, _ = chi2_contingency(contingency_table)\n",
    "        n = contingency_table.sum().sum()\n",
    "        k, r = contingency_table.shape\n",
    "        cramers_v = np.sqrt(chi2 / (n * min(k - 1, r - 1)))\n",
    "        cramers_v_matrix.loc[feature1, feature2] = cramers_v\n",
    "        cramers_v_matrix.loc[feature2, feature1] = cramers_v\n",
    "\n",
    "# Keep upper triangular matrix and sort pairs\n",
    "cramers_v_matrix = cramers_v_matrix.where(np.triu(np.ones(cramers_v_matrix.shape), k=1).astype(bool))\n",
    "correlation_pairs = cramers_v_matrix.unstack().dropna().sort_values(ascending=False)\n",
    "\n",
    "# Low and high correlation splits\n",
    "low_corr = correlation_pairs[correlation_pairs < 0.7].reset_index()\n",
    "low_corr.columns = ['Feature 1', 'Feature 2', 'values']\n",
    "low_corr_feat = pd.unique(low_corr[['Feature 1', 'Feature 2']].values.ravel())\n",
    "\n",
    "correlation_pairs = correlation_pairs[correlation_pairs > 0.7].reset_index()\n",
    "correlation_pairs.columns = ['Feature 1', 'Feature 2', 'correlation']\n",
    "unique_feat = pd.unique(correlation_pairs[['Feature 1', 'Feature 2']].values.ravel())\n",
    "\n",
    "# Correlation with target\n",
    "corr_w_target = pd.concat([feat_x_train_nnum[unique_feat].reset_index(),\n",
    "                           pd.DataFrame(data=y_train, columns=['Claim Injury Type'])], axis=1).corr()['Claim Injury Type'].abs()\n",
    "\n",
    "# Select features to remove\n",
    "features_to_remove = []\n",
    "for col in range(len(correlation_pairs)):\n",
    "    feat1 = correlation_pairs.iloc[col]['Feature 1']\n",
    "    feat2 = correlation_pairs.iloc[col]['Feature 2']\n",
    "    features_to_remove.append(feat1 if abs(corr_w_target[feat1]) >= abs(corr_w_target[feat2]) else feat2)\n",
    "\n",
    "features_to_remove = pd.unique(features_to_remove)\n",
    "\n",
    "# Mark features for Cramér's V selection\n",
    "data_cramer = feat_x_train_nnum.columns[~feat_x_train_nnum.columns.isin(features_to_remove)]\n",
    "cramers = pd.DataFrame(index=feat_x_train_nnum.columns, data=feat_x_train_nnum.columns.isin(data_cramer), columns=['Cramers V'])\n",
    "cramers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Correlations\n",
    "#### 3.2.2.1 Between the features\n",
    "This was made to see if there are redundancy between features. It was considered to be redundant the features with a correlation higher than 0,8 between each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Log Assembly Days</td>\n",
       "      <td>Log C-2 Days</td>\n",
       "      <td>0.816700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C-3 Date Binary</td>\n",
       "      <td>Log C-3 Days</td>\n",
       "      <td>0.899395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First Hearing Date Binary</td>\n",
       "      <td>Log First Hearing Days</td>\n",
       "      <td>0.987633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Feature 1               Feature 2  Correlation\n",
       "0          Log Assembly Days            Log C-2 Days     0.816700\n",
       "1            C-3 Date Binary            Log C-3 Days     0.899395\n",
       "2  First Hearing Date Binary  Log First Hearing Days     0.987633"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the correlation matrix for numerical variables\n",
    "correlation_matrix = feat_x_train_num.corr().abs()\n",
    "\n",
    "# Create a mask to select correlations greater than 0.8\n",
    "high_corr_mask = correlation_matrix > 0.8\n",
    "\n",
    "# Initialize a list to store pairs of variables with high correlations\n",
    "high_corr_pairs = []\n",
    "\n",
    "# Iterate over the mask and store pairs of variables with correlations greater than 0.8\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):  # Avoid duplicate pairs by only checking below the diagonal\n",
    "        if high_corr_mask.iloc[i, j]:\n",
    "            high_corr_pairs.append((correlation_matrix.columns[i], correlation_matrix.columns[j], correlation_matrix.iloc[i, j]))\n",
    "\n",
    "# Create a DataFrame with the variable pairs and their correlations\n",
    "high_corr_df = pd.DataFrame(high_corr_pairs, columns=['Feature 1', 'Feature 2', 'Correlation'])\n",
    "\n",
    "# Display the table of highly correlated variable pairs\n",
    "high_corr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the feature 'Log Assembly Days' and 'Log C-2 Days' are highly correlated, they are considered redudant, but we dont need to drop any as we will see in the later steps which one is more relevant for the model.    \n",
    "The high correlation between 'C-3 Date Binary'\tand 'Log C-3 Days' and between 'First Hearing Date Binary' and 'Log First Hearing Days' will also be analysed further\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2.2 - Correlation with target feature\n",
    "This evaluates the correlation between each feature and the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_series = pd.Series(y_train, index=feat_x_train_num.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation between each feature and the target variable\n",
    "correlation_matrix = feat_x_train_num.corrwith(y_series)\n",
    "\n",
    "# Convert the correlation series to a DataFrame for better readability\n",
    "correlation_df = correlation_matrix.reset_index()\n",
    "correlation_df.columns = ['Feature', 'Correlation_with_Target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Correlation_with_Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age at Injury</td>\n",
       "      <td>0.108248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alternative Dispute Resolution</td>\n",
       "      <td>0.055097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attorney/Representative</td>\n",
       "      <td>0.593608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>District Name</td>\n",
       "      <td>0.022376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gender</td>\n",
       "      <td>0.085855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Medical Fee Region</td>\n",
       "      <td>0.031991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Number of Dependents</td>\n",
       "      <td>0.000354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>log Average Weekly Wage</td>\n",
       "      <td>0.831206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Log C-2 Days</td>\n",
       "      <td>0.116722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Log C-3 Days</td>\n",
       "      <td>0.380316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Log First Hearing Days</td>\n",
       "      <td>0.531830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Log Assembly Days</td>\n",
       "      <td>-0.020568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Day of Week</td>\n",
       "      <td>-0.003395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Day of Month</td>\n",
       "      <td>0.004187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Month</td>\n",
       "      <td>-0.019716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Year</td>\n",
       "      <td>-0.025173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Agreement Reached</td>\n",
       "      <td>0.223614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>C-2 Date Binary</td>\n",
       "      <td>0.170678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>C-3 Date Binary</td>\n",
       "      <td>0.451076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>First Hearing Date Binary</td>\n",
       "      <td>0.529239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Feature  Correlation_with_Target\n",
       "0                    Age at Injury                 0.108248\n",
       "1   Alternative Dispute Resolution                 0.055097\n",
       "2          Attorney/Representative                 0.593608\n",
       "3                    District Name                 0.022376\n",
       "4                           Gender                 0.085855\n",
       "5               Medical Fee Region                 0.031991\n",
       "6             Number of Dependents                 0.000354\n",
       "7          log Average Weekly Wage                 0.831206\n",
       "8                     Log C-2 Days                 0.116722\n",
       "9                     Log C-3 Days                 0.380316\n",
       "10          Log First Hearing Days                 0.531830\n",
       "11               Log Assembly Days                -0.020568\n",
       "12                     Day of Week                -0.003395\n",
       "13                    Day of Month                 0.004187\n",
       "14                           Month                -0.019716\n",
       "15                            Year                -0.025173\n",
       "16               Agreement Reached                 0.223614\n",
       "17                 C-2 Date Binary                 0.170678\n",
       "18                 C-3 Date Binary                 0.451076\n",
       "19       First Hearing Date Binary                 0.529239"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop 'Log Assembly Days' as it was said to be highly correlated with 'Log C-2 Days' and is less related with the target.    \n",
    "We drop 'Log C-3 Days' as it was said to be highly correlated with 'C-3 Date Binary' and is less related with the target.\n",
    "We drop 'First Hearing Date Binary' as it was said to be highly correlated with 'Log First Hearing Days' and is less related with the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=['Log Assembly Days', 'Log C-3 Days','First Hearing Date Binary'])\n",
    "X_test = X_test.drop(columns=['Log Assembly Days','Log C-3 Days','First Hearing Date Binary'])\n",
    "X_final_test = X_final_test.drop(columns=['Log Assembly Days','Log C-3 Days','First Hearing Date Binary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 Kendall (numerical)\n",
    "Kendall's Tau was selected for its resilience to outliers, ensuring more robust correlation analysis when dealing with data that may contain extreme values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Kendall's Tau for each numeric feature\n",
    "kendall_tau_list = []\n",
    "kendall_p_list = []\n",
    "for feature in feat_x_train_num.columns:\n",
    "    tau, p_value = stats.kendalltau(feat_x_train_num[feature], y_train)\n",
    "    kendall_tau_list.append(tau)\n",
    "    kendall_p_list.append(p_value)\n",
    "\n",
    "# Assign the values to a dataframe\n",
    "kendall = pd.DataFrame({'Kendall coefficient': kendall_tau_list, 'Kendall p-value': kendall_p_list}, index=feat_x_train_num.columns)\n",
    "\n",
    "# Filter features based on p-value and Kendall coefficient threshold\n",
    "p_value_threshold = 0.05\n",
    "kendall_tau_threshold = 0.2\n",
    "kendall_selection = pd.DataFrame((kendall['Kendall p-value'] < p_value_threshold) & (kendall['Kendall coefficient'].abs() > kendall_tau_threshold), columns=['Kendall'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Wrapper methods\n",
    "### 3.2.1. RFE (numerical)\n",
    "Recursive Feature Elimination (RFE) helps evaluate the importance of each feature based on its contribution to the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum number of features: 1\n",
      "Score with 1 features: 0.506735\n",
      "Features to select: \n",
      "Age at Injury                     False\n",
      "Alternative Dispute Resolution    False\n",
      "Attorney/Representative           False\n",
      "District Name                     False\n",
      "Gender                             True\n",
      "Medical Fee Region                False\n",
      "Number of Dependents              False\n",
      "log Average Weekly Wage           False\n",
      "Log C-2 Days                      False\n",
      "Log C-3 Days                      False\n",
      "Log First Hearing Days            False\n",
      "Log Assembly Days                 False\n",
      "Day of Week                       False\n",
      "Day of Month                      False\n",
      "Month                             False\n",
      "Year                              False\n",
      "Agreement Reached                 False\n",
      "C-2 Date Binary                   False\n",
      "C-3 Date Binary                   False\n",
      "First Hearing Date Binary         False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=42)\n",
    "\n",
    "#no of features\n",
    "nof_list=np.arange(1,len(feat_x_train_num.columns)+1)            \n",
    "high_score=0\n",
    "#Variable to store the optimum features\n",
    "nof=0           \n",
    "train_score_list =[]\n",
    "val_score_list = []\n",
    "\n",
    "for n in range(len(nof_list)):\n",
    "\n",
    "    #create RFE instance\n",
    "    rfe_num = RFE(estimator = model,n_features_to_select = nof_list[n])\n",
    "    \n",
    "    X_train_rfe = rfe_num.fit_transform(feat_x_train_num,y_train)\n",
    "    X_val_rfe = rfe_num.transform(feat_x_val_num)\n",
    "    \n",
    "\n",
    "    model.fit(X_train_rfe,y_train)\n",
    "    #storing results on training data\n",
    "    train_score = model.score(X_train_rfe,y_train)\n",
    "    train_score_list.append(train_score)\n",
    "    \n",
    "    #storing results on training data\n",
    "    val_score = model.score(X_val_rfe,y_test)\n",
    "    val_score_list.append(val_score)\n",
    "    #check best score\n",
    "    if(val_score > high_score):\n",
    "        high_score = val_score\n",
    "        nof = nof_list[n]\n",
    "        \n",
    "        #adding mention of variables to keep\n",
    "        features_to_select = pd.Series(rfe_num.support_, index = feat_x_train_num.columns)\n",
    "        \n",
    "print(\"Optimum number of features: %d\" %nof)\n",
    "print(\"Score with %d features: %f\" % (nof, high_score))\n",
    "print(f\"Features to select: \\n{features_to_select}\")\n",
    "\n",
    "features_to_select = features_to_select.to_frame()\n",
    "\n",
    "features_to_select.columns=['RFE LR Evaluation']\n",
    "\n",
    "rfe_num = features_to_select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Embedded methods\n",
    "### 3.3.1 Lasso regression (numerical)\n",
    "Lasso Regression was chosen since it helps prevent overfitting and is good for high dimensionality data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Lasso regression instance\n",
    "lasso_reg = LassoCV(random_state=5)\n",
    "# Fitting the data to Lasso regression\n",
    "lasso_reg.fit(feat_x_train_num,y_train)\n",
    "\n",
    "# Assigning the coefficients to the features in a pandas series\n",
    "#(kendall['Kendall p-value'] < p_value_threshold) & (kendall['Kendall coefficient'].abs() > kendall_tau_threshold)\n",
    "lasso = pd.DataFrame({'Lasso coefficient': lasso_reg.coef_}, index=feat_x_train_num.columns)\n",
    "\n",
    "#lasso_coef = pd.DataFrame(lasso_reg.coef_, index=feat_x_train_num.columns)\n",
    "lasso_df = pd.DataFrame(lasso['Lasso coefficient'] > 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2. Ridge Regression\n",
    "Used once it performs well in datasets with highly correlated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Ridge Regression\n",
    "ridge_reg = RidgeCV(alphas=[0.1, 1.0, 10.0], cv=5)  # You can adjust alphas\n",
    "ridge_reg.fit(feat_x_train_num, y_train)\n",
    "\n",
    "# Create a DataFrame with Ridge coefficients and apply the threshold\n",
    "ridge_threshold = 0.10 \n",
    "ridge = pd.DataFrame(\n",
    "    {'Ridge': (np.abs(ridge_reg.coef_) > ridge_threshold)},\n",
    "    index=feat_x_train_num.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Variables chosen\n",
    "The variables were kept if at least one of the previous methods determined that they should be kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RFE LR Evaluation</th>\n",
       "      <th>Lasso coefficient</th>\n",
       "      <th>Kendall</th>\n",
       "      <th>Ridge</th>\n",
       "      <th>Decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age at Injury</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alternative Dispute Resolution</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attorney/Representative</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>District Name</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medical Fee Region</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of Dependents</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log Average Weekly Wage</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log C-2 Days</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log C-3 Days</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log First Hearing Days</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log Assembly Days</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day of Week</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day of Month</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agreement Reached</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-2 Date Binary</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-3 Date Binary</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First Hearing Date Binary</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                RFE LR Evaluation  Lasso coefficient  Kendall  \\\n",
       "Age at Injury                               False              False    False   \n",
       "Alternative Dispute Resolution              False              False    False   \n",
       "Attorney/Representative                     False              False     True   \n",
       "District Name                               False              False    False   \n",
       "Gender                                       True              False    False   \n",
       "Medical Fee Region                          False              False    False   \n",
       "Number of Dependents                        False              False    False   \n",
       "log Average Weekly Wage                     False              False     True   \n",
       "Log C-2 Days                                False              False    False   \n",
       "Log C-3 Days                                False              False     True   \n",
       "Log First Hearing Days                      False              False     True   \n",
       "Log Assembly Days                           False              False    False   \n",
       "Day of Week                                 False              False    False   \n",
       "Day of Month                                False              False    False   \n",
       "Month                                       False              False    False   \n",
       "Year                                        False              False    False   \n",
       "Agreement Reached                           False              False     True   \n",
       "C-2 Date Binary                             False              False    False   \n",
       "C-3 Date Binary                             False              False     True   \n",
       "First Hearing Date Binary                   False              False     True   \n",
       "\n",
       "                                Ridge  Decision  \n",
       "Age at Injury                   False     False  \n",
       "Alternative Dispute Resolution  False     False  \n",
       "Attorney/Representative          True      True  \n",
       "District Name                   False     False  \n",
       "Gender                          False      True  \n",
       "Medical Fee Region              False     False  \n",
       "Number of Dependents            False     False  \n",
       "log Average Weekly Wage          True      True  \n",
       "Log C-2 Days                    False     False  \n",
       "Log C-3 Days                    False      True  \n",
       "Log First Hearing Days           True      True  \n",
       "Log Assembly Days               False     False  \n",
       "Day of Week                     False     False  \n",
       "Day of Month                    False     False  \n",
       "Month                           False     False  \n",
       "Year                            False     False  \n",
       "Agreement Reached                True      True  \n",
       "C-2 Date Binary                  True      True  \n",
       "C-3 Date Binary                  True      True  \n",
       "First Hearing Date Binary        True      True  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.concat([rfe_num, lasso_df, kendall_selection, ridge], axis=1)\n",
    "\n",
    "# Add a 'Decision' column to combine all feature selection methods\n",
    "table['Decision'] = table.apply(lambda row: row.sum() >=1, axis=1)\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numeric features were chosen when they are relevant in at least 1 of the feature selection methods used. This will be the used ones in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the final selected features based on the Decision column (True = selected)\n",
    "selected_features = table[table['Decision'] == True]\n",
    "selected_features_num = selected_features.index.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All categorical features were considered important with Chi-squared and therefore Cramers was calculated and the results obtained in the second one will be the ones considered for use in the future models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features with significant Cramer V results\n",
    "selected_features_cat = cramers\n",
    "selected_features_cat = selected_features_cat[selected_features_cat['Cramers V']==True]\n",
    "\n",
    "# Combine selected categorical and numerical features\n",
    "cat_features = selected_features_cat.index.tolist()\n",
    "all_features = cat_features + selected_features_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Feature scalling and selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify common features between all_features and X_final_test columns\n",
    "common_features = list(set(all_features) & set(X_final_test.columns))\n",
    "\n",
    "# Filter training data with selected features\n",
    "X_train = X_train[common_features]\n",
    "X_test = X_test[common_features]\n",
    "X_final_test = X_final_test[common_features]\n",
    "\n",
    "# Initialize and fit MinMaxScaler on training data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform datasets using the same scaler\n",
    "X_train[common_features] = scaler.transform(X_train)\n",
    "X_test[common_features] = scaler.transform(X_test)\n",
    "X_final_test[common_features] = scaler.transform(X_final_test)\n",
    "\n",
    "# Ensure only selected features remain in each dataset \n",
    "X_train = X_train.loc[:, common_features]\n",
    "X_test = X_test.loc[:, common_features]\n",
    "X_final_test = X_final_test.loc[:, common_features]\n",
    "\n",
    "# Now you can proceed with model training and predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C-2 Date Binary', 'Log First Hearing Days', 'Gender', 'Agreement Reached', 'WCIO Cause of Injury Code', 'County of Injury', 'WCIO Part Of Body Code', 'Attorney/Representative', 'Carrier Type', 'WCIO Nature of Injury Code', 'C-3 Date Binary', 'Zip Code', 'log Average Weekly Wage', 'Industry Code']\n"
     ]
    }
   ],
   "source": [
    "print(common_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the interface\n",
    "pickle.dump(common_features, open(\"common_features.pkl\", 'wb'))\n",
    "pickle.dump(scaler, open(\"scaler.pkl\", 'wb'))\n",
    "\n",
    "pickle.dump(encoder, open(\"encoder.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Evaluation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_predictions(y_pred_train, y_pred_test, y_train = y_train, y_test = y_test):\n",
    "    # Calculate performance metrics for training and testing\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    train_f1_macro = f1_score(y_train, y_pred_train, average='macro')\n",
    "    \n",
    "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    test_f1_macro = f1_score(y_test, y_pred_test, average='macro')\n",
    "\n",
    "    # Display results\n",
    "    print(f\"Accuracy of train: {train_accuracy:.4f}\")\n",
    "    print(f\"Accuracy of test: {test_accuracy:.4f}\")\n",
    "    print(f\"F1 Macro (Train): {train_f1_macro:.4f}\")\n",
    "    print(f\"\\033[1mF1 Macro (Test)\\033[0m: {test_f1_macro:.4f}\")\n",
    "    \n",
    "    print(\"\\nClassification Report for Train Data:\")\n",
    "    print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "    # Return the metrics as a tuple\n",
    "    return train_accuracy, train_f1_macro, test_accuracy, test_f1_macro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Class imbalances\n",
    "To fight the class imbalances we decided to the following different approaches\n",
    "### 4.2.1 Removal of outliers for each injury type in X_train\n",
    "We tried many different approaches for this, including removal with only IQR, only DBSCAN (too computationaly expensive), IQR and DBSCAN ( excellent for detecting outliers in multidimensional feature spaces where relationships between variables are significant) and HDBSCAN.\n",
    "Due to its efficiency, in terms of results and time only HDBSCAN was kept in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1. With HDBSCAN\n",
    "HDBSCAN is a hierarchical version of DBSCAN. It handles noise better and can detect clusters in datasets with different density levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers identified per class (except 5, 6, 7):\n",
      "Class 0: 2157 outliers identified\n",
      "Class 1: 76081 outliers identified\n",
      "Class 3: 41774 outliers identified\n",
      "Class 4: 11115 outliers identified\n",
      "Shape of X_train after removing outliers: (323524, 14)\n"
     ]
    }
   ],
   "source": [
    "# Combine X_train and y_train into a DataFrame for easier processing\n",
    "data_train = pd.DataFrame(X_train)  # Creating DataFrame from X_train\n",
    "data_train['Claim Injury Type'] = y_train  # Add the target variable to the DataFrame\n",
    "\n",
    "# Select only numeric columns from the dataset (assuming no identify_feature_types function)\n",
    "numeric_columns = data_train.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "# Ensure the target column 'Claim Injury Type' is excluded\n",
    "numeric_columns = [col for col in numeric_columns if col != 'Claim Injury Type']\n",
    "data_train = data_train[numeric_columns + ['Claim Injury Type']]  # Include target column for processing\n",
    "\n",
    "# Initialize a dictionary to store the count of outliers by class\n",
    "outliers_per_class = {}\n",
    "outlier_indices_to_drop = []  # List to collect indices of outliers\n",
    "\n",
    "# Iterate over each class, except 5, 6, and 7\n",
    "for injury_type in [0, 1, 3, 4]:  # Replace with relevant classes if needed\n",
    "    # Select the data for the current class\n",
    "    class_data = data_train[data_train['Claim Injury Type'] == injury_type]\n",
    "    X_class = class_data.drop(columns=['Claim Injury Type'])  # Only the features\n",
    "    \n",
    "    # Apply HDBSCAN\n",
    "    dbscan = hdbscan.HDBSCAN(min_samples=3, min_cluster_size=5)  # Tune these parameters if necessary\n",
    "    labels = dbscan.fit_predict(X_class)\n",
    "    \n",
    "    # Count the number of outliers (labels -1 are considered outliers in HDBSCAN)\n",
    "    outliers_count = (labels == -1).sum()\n",
    "    \n",
    "    # Store the count of outliers for the class\n",
    "    outliers_per_class[injury_type] = outliers_count\n",
    "    \n",
    "    # Add the indices of outliers to the list for removal\n",
    "    outlier_indices = class_data.index[labels == -1]\n",
    "    outlier_indices_to_drop.extend(outlier_indices)\n",
    "\n",
    "# Display the number of outliers identified per class\n",
    "print(\"Number of outliers identified per class (except 5, 6, 7):\")\n",
    "for injury_type, count in outliers_per_class.items():\n",
    "    print(f\"Class {injury_type}: {count} outliers identified\")\n",
    "\n",
    "# Remove the identified outliers from the data (only the rows, not the columns)\n",
    "df_DBSCAN = data_train.drop(index=outlier_indices_to_drop)\n",
    "\n",
    "# Separate the features and target variables after removing outliers\n",
    "X_train_DBSCAN = df_DBSCAN.drop(columns=['Claim Injury Type'])\n",
    "y_train_DBSCAN = df_DBSCAN['Claim Injury Type']\n",
    "\n",
    "# Show the shape of the new data\n",
    "print(f\"Shape of X_train after removing outliers: {X_train_DBSCAN.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2. SMOTE\n",
    "SMOTE is a technique of oversampling that generates synthetic samples for the minority class to address class imbalance by creating new data points between existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_DBSCAN_SMOTE, y_train_DBSCAN_SMOTE = smote.fit_resample(X_train_DBSCAN, y_train_DBSCAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_SMOTE, y_train_SMOTE = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE-ENN combines SMOTE with Edited Nearest Neighbors (ENN), which removes noisy or misclassified samples after oversampling, improving data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_train_DBSCAN_SMOTEENN, y_train_DBSCAN_SMOTEENN = smote_enn.fit_resample(X_train_DBSCAN, y_train_DBSCAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3. With Class weights\n",
    "Giving higher weights to minority classes may help address and give them more siginificance to smaller sized classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 6.601390986177257,\n",
       " 1: 0.24667787244940037,\n",
       " 2: 1.0349536531177157,\n",
       " 3: 0.4802827286633032,\n",
       " 4: 1.47239170423338,\n",
       " 5: 16.888967310549777,\n",
       " 6: 728.6073717948718,\n",
       " 7: 152.36293565683647}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "class_weight_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1. Xgboost !!!!!!!!!!\n",
    "The best model was Xgboost therefore we tried different approaches to see which was the best model.\n",
    "Firstly we tried the undersampling of the majory classes with removal of outliers (IQR and HDBSCAN were tried but was erased as the score wasn't good and to enable the notebook to run faster).\n",
    "Second we tried SMOTE and finaly SMOTE-ENN\n",
    "We do a grid-search for the model with DBSCAN as it proved to be the one with the best score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of train: 0.8130\n",
      "Accuracy of test: 0.7963\n",
      "F1 Macro (Train): 0.6616\n",
      "\u001b[1mF1 Macro (Test)\u001b[0m: 0.4312\n",
      "\n",
      "Classification Report for Train Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.42      0.54      2152\n",
      "           1       0.85      0.98      0.91     57597\n",
      "           2       0.47      0.09      0.15     13728\n",
      "           3       0.75      0.88      0.81     29582\n",
      "           4       0.65      0.61      0.63      9650\n",
      "           5       0.12      0.00      0.00       842\n",
      "           6       0.00      0.00      0.00        19\n",
      "           7       0.54      0.33      0.41        93\n",
      "\n",
      "    accuracy                           0.80    113663\n",
      "   macro avg       0.52      0.41      0.43    113663\n",
      "weighted avg       0.76      0.80      0.75    113663\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8130434113198916, 0.661611529701635, 0.7962749531509814, 0.4312231525307739)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the XGBoost Classifier\n",
    "xgb = XGBClassifier(scale_pos_weight=class_weight_dict, n_estimators=500, learning_rate=0.1, random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = xgb.predict(X_train)\n",
    "y_pred_test = xgb.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "evaluate_model_predictions(y_pred_train, y_pred_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of train: 0.8026\n",
      "Accuracy of test: 0.7662\n",
      "F1 Macro (Train): 0.7271\n",
      "\u001b[1mF1 Macro (Test)\u001b[0m: 0.4434\n",
      "\n",
      "Classification Report for Train Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.43      0.53      2152\n",
      "           1       0.86      0.94      0.90     57597\n",
      "           2       0.29      0.23      0.26     13728\n",
      "           3       0.77      0.78      0.78     29582\n",
      "           4       0.64      0.61      0.62      9650\n",
      "           5       0.13      0.03      0.04       842\n",
      "           6       0.00      0.00      0.00        19\n",
      "           7       0.43      0.41      0.42        93\n",
      "\n",
      "    accuracy                           0.77    113663\n",
      "   macro avg       0.48      0.43      0.44    113663\n",
      "weighted avg       0.74      0.77      0.75    113663\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8025648792670714,\n",
       " 0.7270639405181945,\n",
       " 0.7662387936267739,\n",
       " 0.4434419040115678)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the XGBoost Classifier\n",
    "xgb = XGBClassifier(scale_pos_weight=class_weight_dict, n_estimators=500, learning_rate=0.1, random_state=42)\n",
    "xgb.fit(X_train_DBSCAN, y_train_DBSCAN)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = xgb.predict(X_train_DBSCAN)\n",
    "y_pred_test = xgb.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "evaluate_model_predictions(y_pred_train, y_pred_test, y_train_DBSCAN, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of train: 0.8564\n",
      "Accuracy of test: 0.7474\n",
      "F1 Macro (Train): 0.8500\n",
      "\u001b[1mF1 Macro (Test)\u001b[0m: 0.4357\n",
      "\n",
      "Classification Report for Train Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.56      0.50      2152\n",
      "           1       0.87      0.92      0.89     57597\n",
      "           2       0.31      0.22      0.25     13728\n",
      "           3       0.80      0.71      0.75     29582\n",
      "           4       0.59      0.69      0.63      9650\n",
      "           5       0.10      0.32      0.15       842\n",
      "           6       0.00      0.00      0.00        19\n",
      "           7       0.20      0.61      0.30        93\n",
      "\n",
      "    accuracy                           0.75    113663\n",
      "   macro avg       0.41      0.50      0.44    113663\n",
      "weighted avg       0.75      0.75      0.74    113663\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8564297564579472,\n",
       " 0.8499943553522246,\n",
       " 0.7474288026886498,\n",
       " 0.4357449724401471)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the XGBoost Classifier\n",
    "xgb = XGBClassifier(scale_pos_weight=class_weight_dict, n_estimators=500, learning_rate=0.1, random_state=42)\n",
    "xgb.fit(X_train_DBSCAN_SMOTE, y_train_DBSCAN_SMOTE)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = xgb.predict(X_train_DBSCAN_SMOTE)\n",
    "y_pred_test = xgb.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "evaluate_model_predictions(y_pred_train, y_pred_test, y_train_DBSCAN_SMOTE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of train: 0.9102\n",
      "Accuracy of test: 0.7303\n",
      "F1 Macro (Train): 0.8917\n",
      "\u001b[1mF1 Macro (Test)\u001b[0m: 0.4251\n",
      "\n",
      "Classification Report for Train Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.62      0.45      2152\n",
      "           1       0.88      0.88      0.88     57597\n",
      "           2       0.31      0.24      0.27     13728\n",
      "           3       0.82      0.67      0.74     29582\n",
      "           4       0.55      0.75      0.63      9650\n",
      "           5       0.09      0.41      0.15       842\n",
      "           6       0.00      0.00      0.00        19\n",
      "           7       0.18      0.61      0.28        93\n",
      "\n",
      "    accuracy                           0.73    113663\n",
      "   macro avg       0.40      0.52      0.43    113663\n",
      "weighted avg       0.75      0.73      0.74    113663\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9102102202466495,\n",
       " 0.8917226600183217,\n",
       " 0.7303344096143863,\n",
       " 0.42506913352429976)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the XGBoost Classifier\n",
    "xgb = XGBClassifier(\n",
    "    scale_pos_weight=class_weight_dict,  # Optional based on your data balancing\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "xgb.fit(X_train_DBSCAN_SMOTEENN, y_train_DBSCAN_SMOTEENN)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = xgb.predict(X_train_DBSCAN_SMOTEENN)\n",
    "y_pred_test = xgb.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "evaluate_model_predictions(y_pred_train, y_pred_test, y_train_DBSCAN_SMOTEENN, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best parameters found:  {'subsample': 1.0, 'scale_pos_weight': 1, 'reg_lambda': 10, 'reg_alpha': 0, 'n_estimators': 100, 'min_child_weight': 7, 'max_depth': 9, 'learning_rate': 0.2, 'gamma': 0.1, 'colsample_bytree': 0.6}\n",
      "Accuracy of train: 0.8135\n",
      "Accuracy of test: 0.7972\n",
      "F1 Macro (Train): 0.4863\n",
      "\u001b[1mF1 Macro (Test)\u001b[0m: 0.4311\n",
      "\n",
      "Classification Report for Train Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.42      0.54      2152\n",
      "           1       0.85      0.98      0.91     57597\n",
      "           2       0.48      0.09      0.15     13728\n",
      "           3       0.75      0.88      0.81     29582\n",
      "           4       0.66      0.61      0.63      9650\n",
      "           5       0.00      0.00      0.00       842\n",
      "           6       0.00      0.00      0.00        19\n",
      "           7       0.64      0.30      0.41        93\n",
      "\n",
      "    accuracy                           0.80    113663\n",
      "   macro avg       0.52      0.41      0.43    113663\n",
      "weighted avg       0.76      0.80      0.76    113663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define the parameter grid for RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 500, 700],  # Number of trees\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],  # Step size for each iteration\n",
    "    'max_depth': [3, 5, 7, 9],  # Depth of each tree\n",
    "    'min_child_weight': [1, 3, 5, 7],  # Minimum sum of instance weight (hessian) for a child\n",
    "    'subsample': [0.6, 0.8, 1.0],  # Proportion of training data to be used for each boosting round\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],  # Proportion of features to use per tree\n",
    "    'gamma': [0, 0.1, 0.2, 0.5],  # Minimum loss reduction required to make a further partition\n",
    "    'scale_pos_weight': [1, 5, 10, 20],  # Balance of positive and negative weights\n",
    "    'reg_alpha': [0, 0.1, 1, 10],  # L1 regularization term\n",
    "    'reg_lambda': [0, 0.1, 1, 10],  # L2 regularization term\n",
    "}\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb, \n",
    "    param_distributions=param_grid, \n",
    "    n_iter=10,  # Number of random combinations to try\n",
    "    scoring='accuracy',  # Or use 'roc_auc' for classification tasks with imbalanced classes\n",
    "    cv=3,  # Cross-validation splitting\n",
    "    verbose=2,  # Show progress\n",
    "    random_state=42,  # Set random seed for reproducibility\n",
    "    n_jobs=-1  # Use all processors for parallelism\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found by RandomizedSearchCV\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_xgb_model = random_search.best_estimator_\n",
    "\n",
    "# Predictions using the best model\n",
    "y_pred_train = best_xgb_model.predict(X_train)\n",
    "y_pred_test = best_xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_train_xgb_search,f1_train_xgb_search, accuracy_test_xgb_search, f1_test_xgb_search = evaluate_model_predictions(y_pred_train, y_pred_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best parameters found:  {'subsample': 1.0, 'scale_pos_weight': 1, 'reg_lambda': 10, 'reg_alpha': 0, 'n_estimators': 100, 'min_child_weight': 7, 'max_depth': 9, 'learning_rate': 0.2, 'gamma': 0.1, 'colsample_bytree': 0.6}\n",
      "Accuracy of train: 0.8004\n",
      "Accuracy of test: 0.7679\n",
      "F1 Macro (Train): 0.5534\n",
      "\u001b[1mF1 Macro (Test)\u001b[0m: 0.4514\n",
      "\n",
      "Classification Report for Train Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.43      0.54      2152\n",
      "           1       0.86      0.94      0.90     57597\n",
      "           2       0.30      0.23      0.26     13728\n",
      "           3       0.77      0.79      0.78     29582\n",
      "           4       0.65      0.60      0.62      9650\n",
      "           5       0.11      0.02      0.03       842\n",
      "           6       0.00      0.00      0.00        19\n",
      "           7       0.53      0.44      0.48        93\n",
      "\n",
      "    accuracy                           0.77    113663\n",
      "   macro avg       0.49      0.43      0.45    113663\n",
      "weighted avg       0.74      0.77      0.75    113663\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.800401206711094,\n",
       " 0.5534445476841341,\n",
       " 0.7678840079885275,\n",
       " 0.45142368761599255)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define the parameter grid for RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 500, 700],  # Number of trees\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],  # Step size for each iteration\n",
    "    'max_depth': [3, 5, 7, 9],  # Depth of each tree\n",
    "    'min_child_weight': [1, 3, 5, 7],  # Minimum sum of instance weight (hessian) for a child\n",
    "    'subsample': [0.6, 0.8, 1.0],  # Proportion of training data to be used for each boosting round\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],  # Proportion of features to use per tree\n",
    "    'gamma': [0, 0.1, 0.2, 0.5],  # Minimum loss reduction required to make a further partition\n",
    "    'scale_pos_weight': [1, 5, 10, 20],  # Balance of positive and negative weights\n",
    "    'reg_alpha': [0, 0.1, 1, 10],  # L1 regularization term\n",
    "    'reg_lambda': [0, 0.1, 1, 10],  # L2 regularization term\n",
    "}\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb, \n",
    "    param_distributions=param_grid, \n",
    "    n_iter=10,  # Number of random combinations to try\n",
    "    scoring='accuracy',  # Or use 'roc_auc' for classification tasks with imbalanced classes\n",
    "    cv=3,  # Cross-validation splitting\n",
    "    verbose=2,  # Show progress\n",
    "    random_state=42,  # Set random seed for reproducibility\n",
    "    n_jobs=-1  # Use all processors for parallelism\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearchCV\n",
    "random_search.fit(X_train_DBSCAN, y_train_DBSCAN)\n",
    "\n",
    "# Print the best parameters found by RandomizedSearchCV\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_xgb_model = random_search.best_estimator_\n",
    "\n",
    "# Predictions using the best model\n",
    "y_pred_train = best_xgb_model.predict(X_train_DBSCAN)\n",
    "y_pred_test = best_xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model_predictions(y_pred_train, y_pred_test, y_train_DBSCAN, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "xgb_interface = XGBClassifier(\n",
    "    scale_pos_weight=class_weights_dict,  # Usando dicionário de pesos de classes\n",
    "    n_estimators=100,  # Número de rodadas de boosting ajustado para 100\n",
    "    learning_rate=0.2,  # Taxa de aprendizado ajustada para 0.2\n",
    "    random_state=42,\n",
    "    subsample=1.0,  # Manter a proporção de amostragem como 1.0\n",
    "    reg_lambda=10,  # Regularização L2\n",
    "    reg_alpha=0,  # Regularização L1\n",
    "    min_child_weight=7,  # Ajuste para a soma mínima de pesos em uma criança\n",
    "    max_depth=9,  # Profundidade máxima da árvore\n",
    "    gamma=0.1,  # Redução mínima de perda necessária\n",
    "    colsample_bytree=0.6  # Proporção de features para considerar ao construir cada árvore\n",
    ")\n",
    "xgb_interface.fit(X_train_DBSCAN, y_train_DBSCAN)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = xgb_interface.predict(X_train_DBSCAN)\n",
    "y_pred_test = xgb_interface.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to use for interface\n",
    "pickle.dump(xgb_interface, open(\"xgboost.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2. KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of train: 0.8396\n",
      "Accuracy of test: 0.7415\n",
      "F1 Macro (Train): 0.5269\n",
      "\u001b[1mF1 Macro (Test)\u001b[0m: 0.3776\n",
      "\n",
      "Classification Report for Train Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.43      0.43      2152\n",
      "           1       0.85      0.93      0.89     57597\n",
      "           2       0.24      0.16      0.19     13728\n",
      "           3       0.74      0.77      0.76     29582\n",
      "           4       0.56      0.48      0.51      9650\n",
      "           5       0.10      0.02      0.03       842\n",
      "           6       0.00      0.00      0.00        19\n",
      "           7       0.52      0.13      0.21        93\n",
      "\n",
      "    accuracy                           0.74    113663\n",
      "   macro avg       0.43      0.37      0.38    113663\n",
      "weighted avg       0.71      0.74      0.72    113663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize K-Nearest Neighbors classifier with 3 neighbors\n",
    "model_knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Fit the model on training data\n",
    "model_knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict on data\n",
    "y_pred_train_knn = model_knn.predict(X_train)\n",
    "y_pred_test_knn = model_knn.predict(X_test)\n",
    "\n",
    "accuracy_train_knn,f1_train_knn, accuracy_test_knn, f1_test_knn = evaluate_model_predictions(y_pred_train = y_pred_train_knn, y_pred_test = y_pred_test_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3 RandomForestClassifier + Balanced Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of train: 0.8156\n",
      "Accuracy of test: 0.7946\n",
      "F1 Macro (Train): 0.3993\n",
      "\u001b[1mF1 Macro (Test)\u001b[0m: 0.3705\n",
      "\n",
      "Classification Report for Train Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.39      0.52      2152\n",
      "           1       0.85      0.99      0.91     57597\n",
      "           2       0.48      0.07      0.13     13728\n",
      "           3       0.73      0.90      0.81     29582\n",
      "           4       0.68      0.53      0.60      9650\n",
      "           5       0.00      0.00      0.00       842\n",
      "           6       0.00      0.00      0.00        19\n",
      "           7       0.00      0.00      0.00        93\n",
      "\n",
      "    accuracy                           0.79    113663\n",
      "   macro avg       0.44      0.36      0.37    113663\n",
      "weighted avg       0.75      0.79      0.75    113663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_rfc = RandomForestClassifier(n_estimators=100, random_state=42, min_samples_split = 50)\n",
    "\n",
    "model_rfc.fit(X_train, y_train)\n",
    "\n",
    "# Predict on data\n",
    "y_pred_train_rfc = model_rfc.predict(X_train)\n",
    "y_pred_test_rfc = model_rfc.predict(X_test)\n",
    "\n",
    "accuracy_train_rfc,f1_train_rfc, accuracy_test_rfc, f1_test_rfc = evaluate_model_predictions(y_pred_train = y_pred_train_rfc, y_pred_test = y_pred_test_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of train: 0.7028\n",
      "Accuracy of test: 0.6893\n",
      "F1 Macro (Train): 0.4474\n",
      "\u001b[1mF1 Macro (Test)\u001b[0m: 0.3777\n",
      "\n",
      "Classification Report for Train Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.70      0.35      2152\n",
      "           1       0.89      0.85      0.87     57597\n",
      "           2       0.32      0.20      0.25     13728\n",
      "           3       0.84      0.58      0.68     29582\n",
      "           4       0.52      0.76      0.61      9650\n",
      "           5       0.07      0.64      0.13       842\n",
      "           6       0.00      0.00      0.00        19\n",
      "           7       0.07      0.81      0.12        93\n",
      "\n",
      "    accuracy                           0.69    113663\n",
      "   macro avg       0.37      0.57      0.38    113663\n",
      "weighted avg       0.76      0.69      0.71    113663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_rfc_cw = RandomForestClassifier(class_weight=class_weight_dict, n_estimators=100, random_state=42, min_samples_leaf=50)\n",
    "# Fit the model on the training data\n",
    "model_rfc_cw.fit(X_train, y_train)\n",
    "\n",
    "# Predict on training and test sets\n",
    "y_pred_train_rfc_cw = model_rfc_cw.predict(X_train)\n",
    "y_pred_test_rfc_cw = model_rfc_cw.predict(X_test)\n",
    "\n",
    "accuracy_train_rfc_cw, f1_train_rfc_cw, accuracy_test_rfc_cw, f1_test_rfc_cw = evaluate_model_predictions(\n",
    "    y_pred_train=y_pred_train_rfc_cw, \n",
    "    y_pred_test=y_pred_test_rfc_cw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of train: 0.6204\n",
      "Accuracy of test: 0.6189\n",
      "F1 Macro (Train): 0.3217\n",
      "\u001b[1mF1 Macro (Test)\u001b[0m: 0.3181\n",
      "\n",
      "Classification Report for Train Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.64      0.30      2152\n",
      "           1       0.87      0.86      0.87     57597\n",
      "           2       0.29      0.12      0.16     13728\n",
      "           3       0.80      0.42      0.55     29582\n",
      "           4       0.54      0.50      0.52      9650\n",
      "           5       0.05      0.60      0.09       842\n",
      "           6       0.00      0.37      0.00        19\n",
      "           7       0.03      0.87      0.05        93\n",
      "\n",
      "    accuracy                           0.62    113663\n",
      "   macro avg       0.35      0.55      0.32    113663\n",
      "weighted avg       0.73      0.62      0.65    113663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the Balanced Random Forest Classifier\n",
    "brf = BalancedRandomForestClassifier(n_estimators=100, random_state=42)\n",
    "brf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = brf.predict(X_train)\n",
    "y_pred_test = brf.predict(X_test)\n",
    "\n",
    "# Evaluate model using your function\n",
    "accuracy_train_brf,f1_train_brf, accuracy_test_brf, f1_test_brf= evaluate_model_predictions(y_pred_train, y_pred_test, y_train=y_train, y_test=y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.4 MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of train: 0.7893\n",
      "Accuracy of test: 0.7876\n",
      "F1 Macro (Train): 0.3873\n",
      "\u001b[1mF1 Macro (Test)\u001b[0m: 0.3775\n",
      "\n",
      "Classification Report for Train Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.38      0.51      2152\n",
      "           1       0.85      0.98      0.91     57597\n",
      "           2       0.44      0.07      0.12     13728\n",
      "           3       0.73      0.89      0.80     29582\n",
      "           4       0.63      0.50      0.56      9650\n",
      "           5       0.00      0.00      0.00       842\n",
      "           6       0.00      0.00      0.00        19\n",
      "           7       0.37      0.08      0.12        93\n",
      "\n",
      "    accuracy                           0.79    113663\n",
      "   macro avg       0.47      0.36      0.38    113663\n",
      "weighted avg       0.74      0.79      0.74    113663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize an MLPClassifier with specified parameters\n",
    "model_mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42)\n",
    "\n",
    "# Fit the model on training data\n",
    "model_mlp.fit(X_train, y_train)\n",
    "\n",
    "# Predict on data and evaluate performance\n",
    "y_pred_train_mlp = model_mlp.predict(X_train)\n",
    "y_pred_test_mlp = model_mlp.predict(X_test)\n",
    "\n",
    "accuracy_train_mlp,f1_train_mlp, accuracy_test_mlp, f1_test_mlp = evaluate_model_predictions(y_pred_train = y_pred_train_mlp, y_pred_test = y_pred_test_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of train: 0.7609\n",
      "Accuracy of test: 0.7758\n",
      "F1 Macro (Train): 0.4274\n",
      "\u001b[1mF1 Macro (Test)\u001b[0m: 0.3964\n",
      "\n",
      "Classification Report for Train Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.39      0.50      2152\n",
      "           1       0.86      0.97      0.91     57597\n",
      "           2       0.33      0.13      0.19     13728\n",
      "           3       0.75      0.81      0.78     29582\n",
      "           4       0.58      0.58      0.58      9650\n",
      "           5       0.00      0.00      0.00       842\n",
      "           6       0.00      0.00      0.00        19\n",
      "           7       0.27      0.17      0.21        93\n",
      "\n",
      "    accuracy                           0.78    113663\n",
      "   macro avg       0.43      0.38      0.40    113663\n",
      "weighted avg       0.73      0.78      0.75    113663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize an MLPClassifier with specified parameters\n",
    "model_mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42)\n",
    "\n",
    "# Fit the model on training data\n",
    "model_mlp.fit(X_train_DBSCAN, y_train_DBSCAN)\n",
    "\n",
    "# Predict on data and evaluate performance\n",
    "y_pred_train_mlp_DBSCAN = model_mlp.predict(X_train_DBSCAN)\n",
    "y_pred_test_mlp_DBSCAN= model_mlp.predict(X_test)\n",
    "\n",
    "accuracy_train_mlp_hdbscan,f1_train_mlp_hdbscan, accuracy_test_mlp_hdbscan, f1_test_mlp_hdbscan = evaluate_model_predictions(y_pred_train = y_pred_train_mlp_DBSCAN, y_pred_test = y_pred_test_mlp_DBSCAN, y_train =y_train_DBSCAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.5 LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of train: 0.7700\n",
      "Accuracy of test: 0.7706\n",
      "F1 Macro (Train): 0.3217\n",
      "\u001b[1mF1 Macro (Test)\u001b[0m: 0.3212\n",
      "\n",
      "Classification Report for Train Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.23      0.34      2152\n",
      "           1       0.84      0.98      0.91     57597\n",
      "           2       0.34      0.06      0.10     13728\n",
      "           3       0.70      0.89      0.79     29582\n",
      "           4       0.57      0.36      0.44      9650\n",
      "           5       0.00      0.00      0.00       842\n",
      "           6       0.00      0.00      0.00        19\n",
      "           7       0.00      0.00      0.00        93\n",
      "\n",
      "    accuracy                           0.77    113663\n",
      "   macro avg       0.38      0.32      0.32    113663\n",
      "weighted avg       0.71      0.77      0.72    113663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Logistic Regression classifier\n",
    "model_lr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Fit the model on training data\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on training data and evaluate performance\n",
    "y_pred_train_lr = model_lr.predict(X_train)\n",
    "y_pred_test_lr = model_lr.predict(X_test)\n",
    "\n",
    "accuracy_train_lr,f1_train_lr, accuracy_test_lr, f1_test_lr = evaluate_model_predictions(y_pred_train = y_pred_train_lr, y_pred_test = y_pred_test_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Model Assessment\n",
    "This section serves to understand which is the best model and the overfiting in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Train F1 Score</th>\n",
       "      <th>Test F1 Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Simple Models</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGB_Search</th>\n",
       "      <td>0.813516</td>\n",
       "      <td>0.797243</td>\n",
       "      <td>0.486335</td>\n",
       "      <td>0.431122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.839618</td>\n",
       "      <td>0.741473</td>\n",
       "      <td>0.526937</td>\n",
       "      <td>0.377560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.815639</td>\n",
       "      <td>0.794595</td>\n",
       "      <td>0.399284</td>\n",
       "      <td>0.370521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_CW</th>\n",
       "      <td>0.702790</td>\n",
       "      <td>0.689274</td>\n",
       "      <td>0.447357</td>\n",
       "      <td>0.377729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BalancedRF</th>\n",
       "      <td>0.620441</td>\n",
       "      <td>0.618909</td>\n",
       "      <td>0.321706</td>\n",
       "      <td>0.318070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.789335</td>\n",
       "      <td>0.787618</td>\n",
       "      <td>0.387319</td>\n",
       "      <td>0.377503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticR</th>\n",
       "      <td>0.770048</td>\n",
       "      <td>0.770638</td>\n",
       "      <td>0.321694</td>\n",
       "      <td>0.321182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Train Accuracy  Test Accuracy  Train F1 Score  Test F1 Score\n",
       "Simple Models                                                              \n",
       "XGB_Search           0.813516       0.797243        0.486335       0.431122\n",
       "KNN                  0.839618       0.741473        0.526937       0.377560\n",
       "RF                   0.815639       0.794595        0.399284       0.370521\n",
       "RF_CW                0.702790       0.689274        0.447357       0.377729\n",
       "BalancedRF           0.620441       0.618909        0.321706       0.318070\n",
       "MLP                  0.789335       0.787618        0.387319       0.377503\n",
       "LogisticR            0.770048       0.770638        0.321694       0.321182"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define model results dictionary\n",
    "model_results = {\n",
    "    'Simple Models': [\n",
    "        'XGB_Search', 'KNN', 'RF', 'RF_CW', 'BalancedRF',\n",
    "        'MLP', 'LogisticR'\n",
    "    ],\n",
    "    'Train Accuracy': [\n",
    "        accuracy_train_xgb_search, accuracy_train_knn, accuracy_train_rfc, \n",
    "        accuracy_train_rfc_cw, accuracy_train_brf, accuracy_train_mlp, accuracy_train_lr\n",
    "    ],\n",
    "    'Test Accuracy': [\n",
    "        accuracy_test_xgb_search, accuracy_test_knn, accuracy_test_rfc, \n",
    "        accuracy_test_rfc_cw, accuracy_test_brf, accuracy_test_mlp, accuracy_test_lr\n",
    "    ],\n",
    "    'Train F1 Score': [\n",
    "        f1_train_xgb_search, f1_train_knn, f1_train_rfc, \n",
    "        f1_train_rfc_cw, f1_train_brf, f1_train_mlp, f1_train_lr\n",
    "    ],\n",
    "    'Test F1 Score': [\n",
    "        f1_test_xgb_search, f1_test_knn, f1_test_rfc, \n",
    "        f1_test_rfc_cw, f1_test_brf, f1_test_mlp, f1_test_lr\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create DataFrame with the results\n",
    "results_models = pd.DataFrame(model_results)\n",
    "\n",
    "# Set 'Simple Models' column as the index\n",
    "results_models.set_index('Simple Models', inplace=True)\n",
    "\n",
    "# Display the DataFrame with results\n",
    "results_models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set model names from the 'results_models' DataFrame\n",
    "model_names = results_models.index\n",
    "\n",
    "# Accuracy and F1 scores from the results DataFrame\n",
    "train_accuracy = results_models['Train Accuracy']\n",
    "test_accuracy = results_models['Test Accuracy']\n",
    "train_f1 = results_models['Train F1 Score']\n",
    "test_f1 = results_models['Test F1 Score']\n",
    "\n",
    "# Bar width\n",
    "bar_width = 0.3\n",
    "index = np.arange(len(model_names))\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot bars for Train Accuracy, Test Accuracy, Train F1 Score, and Test F1 Score\n",
    "bar_tra = ax.bar(index - bar_width / 2, train_accuracy, bar_width, label='Train Accuracy', color='#1F77B4' )\n",
    "bar_ta = ax.bar(index - bar_width / 2, test_accuracy, bar_width, label='Test Accuracy', color='#AEC7E8')\n",
    "\n",
    "bar_trf = ax.bar(index + bar_width / 2, train_f1, bar_width, label='Train F1 Score', alpha=0.7, color= '#2CA02C' )\n",
    "bar_tf = ax.bar(index + bar_width / 2, test_f1, bar_width, label='Test F1 Score', alpha=0.7, color='#98DF8A')\n",
    "\n",
    "# Labeling the plot\n",
    "ax.set_ylabel('Scores', fontsize=12)\n",
    "ax.set_title('Comparison of Model Performance (Accuracy & F1 Score)', fontsize=14)\n",
    "\n",
    "# Set the model names on the x-axis from 'results_models' index\n",
    "ax.set_xticks(index)\n",
    "ax.set_xticklabels(model_names)\n",
    "\n",
    "# Display the legend\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot with tight layout to ensure no labels are cut off\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with best F1-Score (macro) is XGB therefore this will be the model explored the most in the next notebook with cross validation and different strategies to fight class imbalance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
