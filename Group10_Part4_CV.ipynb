{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "383fd3b5",
   "metadata": {},
   "source": [
    "Students:\n",
    "\n",
    "Joana Rodrigues - 20240603    \n",
    "Maria Francisca - 20240346     \n",
    "Rui Reis - 20240854      \n",
    "Tomás Silva - 20230982     \n",
    "Victor Pita - 20240596        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee84d91",
   "metadata": {},
   "source": [
    "# Project Part 4 - Model tuning with Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4669302a",
   "metadata": {},
   "source": [
    "This thrid part contains the tuning of the model. In other words, cross validation is done in the best model registered in the previous notebook and some strategies to fight class imbalance are tried."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fff682",
   "metadata": {},
   "source": [
    "# Index \n",
    "1. [Imports](#imports)   \n",
    "    1.1. [Import Libraries](#importlibraries)    \n",
    "    1.2. [Import Data files](#importfiles)\n",
    "2. [Data exploration and Preprocessing](#data)   \n",
    "    2.1. [Define index](#index)    \n",
    "    2.2. [Dataset columns](#columns)  \n",
    "    2.3. [Functions](#functions)   \n",
    "    2.4. [New Features](#newfeatures)       \n",
    "    2.5. [1st Exploration: Univariate Distributions](#1stexploration)     \n",
    "    2.6. [EDA](#eda)    \n",
    "    2.7. [Univariate EDA: Descriptive Summary](#descriptivesummary)     \n",
    "    2.8. [Univariate EDA: Missing Values](#missingvalues)     \n",
    "    2.9. [Univariate EDA: Categorical & Numerical](#categoricalnumerical)       \n",
    "    2.9.1. [Categorical - Distributions](#categoricaldistributions)            \n",
    "    2.9.2. [Numerical - Distributions](#numericaldistributions)        \n",
    "    2.10. [Multivariate EDA: Categorical & Numerical](#multivariateeda)      \n",
    "    2.10.1. [Numerical - Categorical - KDE Plots](#kdeplots)       \n",
    "    2.10.2. [Categorical - Categorical - Plots](#categoricalplots)        \n",
    "    2.10.3. [Numerical - Numerical - Plots](#numericalplots)           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb1fe21",
   "metadata": {},
   "source": [
    "`Accident Date` Injury date of the claim   \n",
    "`Age at Injury Age` of injured worker when the injury occurred.  \n",
    "`Alternative Dispute Resolution` Adjudication processes external to the Board.   \n",
    "`Assembly Date` The date the claim was first assembled.   \n",
    "`Attorney/ Representative` Is the claim being represented by an Attorney?   \n",
    "`Average Weekly Wage ` The wage used to calculate workers’ compensation, disability, or an Paid Leave wage replacement benefits.      \n",
    "`Birth Year` The reported year of birth of the injured worker.   \n",
    "`C-2 Date` Date of receipt of the Employer's Report of Work-Related; Injury/Illness or equivalent (formerly Form C-2).   \n",
    "`C-3 Date` Date Form C-3 (Employee Claim Form) was received.   \n",
    "`Carrier Name`Name of primary insurance provider responsible for providing workers’ compensation coverage to the injured worker’s employer.   \n",
    "`Carrier Type` Type of primary insurance provider responsible for providing workers’ compensation coverage.   \n",
    "`Claim Identifier` Unique identifier for each claim, assigned by WCB.   \n",
    "`County of Injury` Name of the New York County where the injury occurred.   \n",
    "`COVID-19 Indicator` Indication that the claim may be associated with COVID-19.   \n",
    "`District Name` Name of the WCB district office that oversees claims for that region or area of the state.   \n",
    "`First Hearing Date` Date the first hearing was held on a claim at a WCB hearing location. A blank date means the claim has not yet had a hearing held.    \n",
    "`Gender` The reported gender of the injured worker.   \n",
    "`IME-4 Count` Number of IME-4 forms received per claim. The IME-4 form is the “Independent Examiner's Report of Independent Medical Examination” form.   \n",
    "`Industry Code` NAICS code and descriptions are available at: https://www.naics.com/search-naics-codes-by-industry/.   \n",
    "`Industry Code Description` 2-digit NAICS industry code description used to classify businesses according to their economic activity.   \n",
    "`Medical Fee Region` Approximate region where the injured worker would receive medical service.   \n",
    "`OIICS Nature of Injury Description` The OIICS nature of injury codes & descriptions are available at https://www.bls.gov/iif/oiics_manual_2007.pdf.   \n",
    "`WCIO Cause of Injury Code` The WCIO cause of injury codes & descriptions are at https://www.wcio.org/Active%20PNC/WCIO_Cause_Table.pdf   \n",
    "`WCIO Cause of Injury Description` See description of field above.    \n",
    "`WCIO Nature of Injury Code` The WCIO nature of injury are available at https://www.wcio.org/Active%20PNC/WCIO_Nature_Table.pdf   \n",
    "`WCIO Nature of Injury Description`See description of field above.   \n",
    "`WCIO Part Of Body Code` The WCIO part of body codes & descriptions are available athttps://www.wcio.org/Active%20PNC/WCIO_Part_Table.pdf   \n",
    "`WCIO Part Of Body Description` See description of field above.   \n",
    "`Zip Code` The reported ZIP code of the injured worker’s home address.   \n",
    "`Agreement Reached` Binary variable: Yes if there is an agreement without the involvement of the WCB -> unknown at the start of a claim.   \n",
    "`WCB Decision` Multiclass variable: Decision of the WCB relative to the claim: “Accident” means that claim refers to workplace accident, “Occupational Disease” means illness from the workplace. -> requires WCB deliberation so it is unknown at start of claim.    \n",
    "`Claim Injury Type` Main target variable: Deliberation of the WCB relative to benefits awarded to the claim. Numbering indicates severity   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bbb358",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"imports\">\n",
    "    \n",
    "# 1. Import\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f86215e",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"importlibraries\">\n",
    "    \n",
    "## 1.1. Import libraries\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9691eeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import warnings\n",
    "import itertools\n",
    "import math\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler,LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import pickle\n",
    "import category_encoders as ce\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight\n",
    "import hdbscan\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74765ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51467006",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"importfiles\">\n",
    "    \n",
    "## 1.2. Import data files\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c47af510",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pickle.load(open(\"df_train_cleaned.pkl\", 'rb'))\n",
    "df_test = pickle.load(open(\"df_test_cleaned.pkl\", 'rb'))\n",
    "features_selected = pickle.load(open(\"common_features.pkl\", 'rb')) # features selected in the previous notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce362cf6",
   "metadata": {},
   "source": [
    "Separation of target and other variables and encoding of the target.        \n",
    "Labelencoder is used in this case as the 'Claim Injury Type' can be considered ordinal because there are injury types worse than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bb29b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(columns=['Claim Injury Type'])  # Features\n",
    "y = df_train['Claim Injury Type']  # Target column\n",
    "target_le = LabelEncoder()\n",
    "target_le.fit(y)\n",
    "y = pd.Series(target_le.transform(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793b010d",
   "metadata": {},
   "source": [
    "Feature selection     \n",
    "To understand if the CV works better than the standard data split we use the same features as were used in the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15577550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(387975, 34)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de3992ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[features_selected]\n",
    "df_test = df_test[features_selected]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b389e5a",
   "metadata": {},
   "source": [
    "### Function that defines the feature types      \n",
    "(Same function as in the previous notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acd2970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_feature_types(df):\n",
    "    # Identifying date features\n",
    "    date_features = [column for column in df.columns if 'Date' in column]\n",
    "    \n",
    "    # Identifying categorical (object) features initially\n",
    "    categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    # Identifying boolean features\n",
    "    boolean_features = df.select_dtypes(include=['bool']).columns.tolist()\n",
    "    \n",
    "    # Identifying numerical features (integers and floats), but excluding those with 'Code', 'County', or 'Carrier' in their name\n",
    "    numerical_features = [\n",
    "        column for column in df.select_dtypes(include=['int64', 'float64']).columns\n",
    "        if 'Code' not in column and 'County' not in column and 'Carrier' not in column and 'Decision' not in column and 'Indicator' not in column  and 'Grouped' not in column\n",
    "    ]\n",
    "    \n",
    "    # Adding features with 'Code', 'County', or 'Carrier' in the name to categorical features, even if they are numerical\n",
    "    categorical_features.extend([\n",
    "        column for column in df.columns if 'Code' in column or 'County' in column or 'Carrier' in column or 'Decision' in column or 'Grouped' in column\n",
    "    ])\n",
    "\n",
    "    # Removing duplicates in case any feature is accidentally added twice\n",
    "    categorical_features = list(set(categorical_features))\n",
    "    \n",
    "    return {\n",
    "        'date_features': date_features,\n",
    "        'numerical_features': numerical_features,\n",
    "        'categorical_features': categorical_features,\n",
    "        'boolean_features': boolean_features\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb240fa",
   "metadata": {},
   "source": [
    "### Function that handles the missing values      \n",
    "For the numerical columns it replaces them with the median due to not having removed the outliers, this value seems a better approach    \n",
    "For the categorical columns we substitute the missing values with the mode. Initially, we thought about substituting the missing values of the categoricals according to the mode for each type of injury but as there are not a lot of missing values in this stage, we went for a simpler approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc9fbea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(X_train, X_val, df_test):\n",
    "    # Identify feature types\n",
    "    feature_types = identify_feature_types(X_train)\n",
    "    \n",
    "    # For numerical columns: fill NaN with the median value (to avoid outlier influence)\n",
    "    numerical_features = feature_types['numerical_features']\n",
    "    \n",
    "    for column in numerical_features:\n",
    "        if column in X_train.columns:\n",
    "            # Use the median value of the training set for filling missing values\n",
    "            median_value = X_train[column].median()  # Using median to handle potential outliers\n",
    "            X_train[column] = X_train[column].fillna(median_value)\n",
    "            X_val[column] = X_val[column].fillna(median_value)\n",
    "            df_test[column] = df_test[column].fillna(median_value)\n",
    "\n",
    "    # For categorical columns: fill NaN with the mode (most frequent value)\n",
    "    categorical_features = feature_types['categorical_features']\n",
    "    \n",
    "    for column in categorical_features:\n",
    "        if column in X_train.columns:\n",
    "            # Use the mode value of the training set for filling missing values\n",
    "            mode_value = X_train[column].mode()[0]  # Find the mode (most frequent value) for each categorical column\n",
    "            X_train[column] = X_train[column].fillna(mode_value)\n",
    "            X_val[column] = X_val[column].fillna(mode_value)\n",
    "            df_test[column] = df_test[column].fillna(mode_value)\n",
    "\n",
    "    # print(\"Columns with missing values in X_train:\")\n",
    "    # print(X_train.columns[X_train.isna().any()].tolist())  # Using .any() to check for any NaNs in each column\n",
    "    # print(\"Columns with missing values in X_val:\")\n",
    "    # print(X_val.columns[X_val.isna().any()].tolist())\n",
    "    # print(\"Columns with missing values in df_test:\")\n",
    "    # print(df_test.columns[df_test.isna().any()].tolist())\n",
    "    return X_train, X_val, df_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a505aa6",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "The encoder chosen was CountEncoder because it represents categorical values based on their frequency, providing a meaningful numerical encoding. Unlike other encoders that assign arbitrary numbers to categories, CountEncoder avoids the risk of introducing misleading patterns or biases into the model, which could potentially mislead the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e33411db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_placeholders(df):\n",
    "    for col in df.columns:\n",
    "        unique_vals = df[col].unique()\n",
    "        print(f\"Column: {col}\")\n",
    "        print(f\"Unique values: {unique_vals}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "def encoder(X_train, X_val, df_test):\n",
    "    # Identify categorical columns\n",
    "    columns_to_encode = [col for col in X_train.columns if X_train[col].dtype == 'object']\n",
    "    encoder = ce.CountEncoder()\n",
    "\n",
    "    # Create copies of the input DataFrames to avoid modifying the originals\n",
    "    X_train_encoded = X_train.copy()\n",
    "    X_val_encoded = X_val.copy()\n",
    "    X_test_encoded = df_test.copy()\n",
    "\n",
    "    for col in columns_to_encode:\n",
    "        # Fit encoder only on the training set\n",
    "        encoder.fit(X_train[[col]])\n",
    "\n",
    "        # Transform the training, validation, and test sets using the same encoding\n",
    "        X_train_encoded[col] = encoder.transform(X_train[[col]])\n",
    "        X_val_encoded[col] = encoder.transform(X_val[[col]]).fillna(0)  # Handle unseen categories in validation\n",
    "        X_test_encoded[col] = encoder.transform(df_test[[col]]).fillna(0)  # Handle unseen categories in test\n",
    "\n",
    "    # check_placeholders(X_train_encoded)\n",
    "    # check_placeholders(X_val_encoded)\n",
    "    # check_placeholders(X_test_encoded)\n",
    "    # print(X_train_encoded.dtypes)\n",
    "    # print(X_val_encoded.dtypes)\n",
    "    # print(X_test_encoded.dtypes)\n",
    "\n",
    "\n",
    "    return X_train_encoded, X_val_encoded, X_test_encoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36813c9",
   "metadata": {},
   "source": [
    "### Scaler\n",
    "The scaler chosen was MinMaxScale because, even though there were some outliers in the data, the transformation made to log features helped reduce this differences and therefore the outliers are not extreme. Furthermore, this scaler also works well with data that does not follow a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45e34f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler(X_train, X_val, df_test):\n",
    "    metric_features = [col for col in X_train.columns if pd.api.types.is_numeric_dtype(X_train[col])]\n",
    "\n",
    "    # Scale numeric features\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_val_scaled = X_val.copy()\n",
    "    X_test_scaled = df_test.copy()\n",
    "\n",
    "    X_train_scaled[metric_features] = scaler.fit_transform(X_train)\n",
    "    X_val_scaled[metric_features] = scaler.transform(X_val)\n",
    "    X_test_scaled[metric_features] = scaler.transform(X_test_scaled)\n",
    "\n",
    "    return X_train_scaled, X_val_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c6334c",
   "metadata": {},
   "source": [
    "### Evaluation of model\n",
    "This function is to be incorporated to understand if the changes made in the models worked for the better or not.\n",
    "It allows to see if the classes are being well predicted and if not if they are being predicted at all or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c31bfde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_predictions(y_pred_train, y_pred_val, y_train, y_val):\n",
    "    # Calculate performance metrics for training and testing\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    train_f1_macro = f1_score(y_train, y_pred_train, average='macro')\n",
    "    \n",
    "    test_accuracy = accuracy_score(y_val, y_pred_val)\n",
    "    test_f1_macro = f1_score(y_val, y_pred_val, average='macro')\n",
    "\n",
    "    # Display results\n",
    "    print(f\"Accuracy of train: {train_accuracy:.4f}\")\n",
    "    print(f\"Accuracy of test: {test_accuracy:.4f}\")\n",
    "    print(f\"F1 Macro (Train): {train_f1_macro:.4f}\")\n",
    "    print(f\"\\033[1mF1 Macro (Test)\\033[0m: {test_f1_macro:.4f}\")\n",
    "    \n",
    "    print(\"\\nClassification Report for Validation Data:\")\n",
    "    print(classification_report(y_val, y_pred_val))\n",
    "\n",
    "    print(\"\\Confusion Matrix for Validation Data:\")\n",
    "    print(confusion_matrix(y_val, y_pred_val))\n",
    "    return train_accuracy, train_f1_macro, test_accuracy, test_f1_macro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e17a45",
   "metadata": {},
   "source": [
    "### HDBSCAN for undersampling\n",
    "Since the outliers were not removed initially, we decided to address them by removing the outliers for each injury type class separately. This approach helps ensure that each injury type has more consistent values and prevents confusion with other injury types, where outliers might resemble the values of different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97051bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_remover(X_train, y_train):\n",
    "    # Combine X_train and y_train into a single DataFrame for easier processing\n",
    "    data_train = pd.DataFrame(X_train)\n",
    "    data_train['Claim Injury Type'] = y_train  # Add the target variable\n",
    "\n",
    "    # Select only numeric columns from the dataset\n",
    "    numeric_columns = data_train.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "    # Ensure the target column 'Claim Injury Type' is excluded from numeric columns\n",
    "    numeric_columns = [col for col in numeric_columns if col != 'Claim Injury Type']\n",
    "    data_train = data_train[numeric_columns + ['Claim Injury Type']]  # Reorganize columns\n",
    "\n",
    "    # Initialize a dictionary to store the count of outliers by class\n",
    "    outliers_per_class = {}\n",
    "    outlier_indices_to_drop = []  # List to collect indices of outliers\n",
    "\n",
    "    # Iterate over each class, except 5, 6, and 7\n",
    "    for injury_type in [0,1, 2, 3, 4]:  \n",
    "        # Select the data for the current class\n",
    "        class_data = data_train[data_train['Claim Injury Type'] == injury_type]\n",
    "        X_class = class_data.drop(columns=['Claim Injury Type'])  # Only the features\n",
    "\n",
    "        # Apply HDBSCAN\n",
    "        dbscan = hdbscan.HDBSCAN(min_samples=3, min_cluster_size=5)  # Adjust parameters if needed\n",
    "        labels = dbscan.fit_predict(X_class)\n",
    "\n",
    "        # Count the number of outliers (labels == -1 are outliers in HDBSCAN)\n",
    "        outliers_count = (labels == -1).sum()\n",
    "\n",
    "        # Store the count of outliers for the class\n",
    "        outliers_per_class[injury_type] = outliers_count\n",
    "\n",
    "        # Add the indices of outliers to the list for removal\n",
    "        outlier_indices = class_data.index[labels == -1]\n",
    "        outlier_indices_to_drop.extend(outlier_indices)\n",
    "\n",
    "    # Display the number of outliers identified per class\n",
    "    print(\"Number of outliers identified per class (except 5, 6, 7):\")\n",
    "    for injury_type, count in outliers_per_class.items():\n",
    "        print(f\"Class {injury_type}: {count} outliers identified\")\n",
    "\n",
    "    # Remove the identified outliers from the data\n",
    "    df_DBSCAN = data_train.drop(index=outlier_indices_to_drop)\n",
    "\n",
    "    # Separate the features and target variables after removing outliers\n",
    "    X_train_DBSCAN = df_DBSCAN.drop(columns=['Claim Injury Type'])\n",
    "    y_train_DBSCAN = df_DBSCAN['Claim Injury Type']\n",
    "\n",
    "    # Show the shape of the new data\n",
    "    print(f\"Shape of X_train after removing outliers: {X_train_DBSCAN.shape}\")\n",
    "\n",
    "    return X_train_DBSCAN, y_train_DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b30615",
   "metadata": {},
   "source": [
    "### Cross-validation function\n",
    "The following function performs cross-validation on the model chosen, evaluating its performance on multiple splits of training and validation data.     \n",
    "It initializes a StratifiedKFold cross-validation with 3 splits. For each fold, the function splits the data into training and validation sets, handles missing values, encodes categorical variables, and scales the features (with the functions previously set).    \n",
    "Optionally, it applies some techniques of undersampling and oversampling.\n",
    "If specified the function will apply the previous function on the model (to remove the outliers per class with HDBSCAN) and if specified it will do a SMOTE for the smallest class (6).     \n",
    "After each fold, it measures the time taken and evaluates the model’s predictions for both training and validation data.    \n",
    "Finally, the function predicts on the test set and returns these predictions, to use for the submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a18ac2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_score(model, X, y, df_test, feature_selection=False, smote=False, hdbscan= False):\n",
    "    skf = StratifiedKFold(n_splits=3)\n",
    "    timer = []\n",
    "    \n",
    "    for train_index, val_index in skf.split(X, y):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        begin = time.perf_counter()\n",
    "\n",
    "        handle_missing_values(X_train, X_val, df_test)\n",
    "        \n",
    "        X_train_encoded, X_val_encoded, X_test_encoded = encoder(X_train, X_val, df_test)\n",
    "        X_train_scaled, X_val_scaled, X_test_scaled = scaler(X_train_encoded, X_val_encoded, X_test_encoded)\n",
    "        \n",
    "        if hdbscan:\n",
    "            X_train_scaled, y_train = outliers_remover(X_train_scaled, y_train)\n",
    "\n",
    "        if smote:\n",
    "            oversampler = SMOTE(sampling_strategy={6: 6000}, random_state=42)\n",
    "            X_train_scaled, y_train = oversampler.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred_train = model.predict(X_train_scaled)  # Predições no conjunto de treino\n",
    "        y_pred_val = model.predict(X_val_scaled)  # Predições no conjunto de validação\n",
    "        end = time.perf_counter()\n",
    "\n",
    "        timer.append(end - begin)\n",
    "\n",
    "        print(f\"Fold duration: {end - begin:.2f}s\")\n",
    "    train_accuracy, train_f1_macro, test_accuracy, test_f1_macro = evaluate_model_predictions(y_pred_train, y_pred_val, y_train=y_train, y_val=y_val)\n",
    "\n",
    "    y_pred_test = model.predict(X_test_scaled)\n",
    "    \n",
    "    print(\"Predictions completed.\")\n",
    "    return y_pred_test, train_accuracy, train_f1_macro, test_accuracy, test_f1_macro\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0e3673",
   "metadata": {},
   "source": [
    "### Model chosen\n",
    "The model chosen is taking into account the previous notebooks' results.    \n",
    "XGBoost seemed to be the best model to predict our data and therefore will be explored further in this notebook with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef0af704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "xgb = XGBClassifier(\n",
    "    scale_pos_weight=class_weights_dict,  # Usando dicionário de pesos de classes\n",
    "    n_estimators=100,  # Número de rodadas de boosting ajustado para 100\n",
    "    learning_rate=0.2,  # Taxa de aprendizado ajustada para 0.2\n",
    "    random_state=42,\n",
    "    subsample=1.0,  # Manter a proporção de amostragem como 1.0\n",
    "    reg_lambda=10,  # Regularização L2\n",
    "    reg_alpha=0,  # Regularização L1\n",
    "    min_child_weight=7,  # Ajuste para a soma mínima de pesos em uma criança\n",
    "    max_depth=9,  # Profundidade máxima da árvore\n",
    "    gamma=0.1,  # Redução mínima de perda necessária\n",
    "    colsample_bytree=0.6  # Proporção de features para considerar ao construir cada árvore\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71fb21d",
   "metadata": {},
   "source": [
    "### XGB simple model\n",
    "Trying the model that proved to be the best from the previous notebook with cross validation.    \n",
    "For comparison purposes this model is simple with no undersampling or oversampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27344b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold duration: 38.70s\n"
     ]
    }
   ],
   "source": [
    "y_pred_test_xgb, train_accuracy_xgb, train_f1_macro_xgb, test_accuracy_xgb, test_f1_macro_xgb = avg_score(model=xgb, X=X, y=y, df_test=df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430d9a25",
   "metadata": {},
   "source": [
    "### XGB with RandomUnderSampler\n",
    "As some of the classes are highly representative of the dataset, we use the RandomUnderSampler technique to address class imbalance by randomly undersampling the majority classes, ensuring a more balanced distribution of classes for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f964923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the original class distribution\n",
    "print(\"Original class distribution:\", Counter(y))\n",
    "\n",
    "# Apply RandomUnderSampler to reduce the size of majority classes\n",
    "under_sampler = RandomUnderSampler(sampling_strategy={1: 150000, 3: 40000, 2: 40000, 4: 30000, 0: 8000, 5: 4207, 7: 466, 6: 97}, random_state=42)\n",
    "\n",
    "# Fit the undersampling model to the data\n",
    "X_resampled, y_resampled = under_sampler.fit_resample(X, y)\n",
    "\n",
    "# Check the class distribution after undersampling\n",
    "print(\"Distribution after undersampling:\", Counter(y_resampled))\n",
    "\n",
    "# Run the model\n",
    "y_pred_test_xgbrus, train_accuracy_xgbrus, train_f1_macro_xgbrus, test_accuracy_xgbrus, test_f1_macro_xgbrus = avg_score(model=xgb, X=X_resampled, y=y_resampled, df_test=df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b0a2dd",
   "metadata": {},
   "source": [
    "### XGB with SMOTE and RandomUnderSampler\n",
    "As previously seen the model made is having a hard time predicting some of the minority classes, to try to avoid this, we develop a model with undersampling of the minority classes through randomundersampling and oversampling of the class 6 through SMOTE (as class 6 is harder to predict than 5).       \n",
    "(SMOTE-ENN was also tried as it was in the previous notebook but didn't obtain as good results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81383709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the original class distribution\n",
    "print(\"Original class distribution:\", Counter(y))\n",
    "\n",
    "# Apply RandomUnderSampler to reduce the size of majority classes\n",
    "under_sampler = RandomUnderSampler(sampling_strategy={1: 150000, 3: 40000, 2: 40000, 4: 30000, 0: 8000, 5: 4207, 7: 466, 6: 97}, random_state=42)\n",
    "\n",
    "# Fit the undersampling model to the data\n",
    "X_resampled, y_resampled = under_sampler.fit_resample(X, y)\n",
    "\n",
    "# Check the class distribution after undersampling\n",
    "print(\"Distribution after undersampling:\", Counter(y_resampled))\n",
    "\n",
    "# Run the model\n",
    "y_pred_test_xgbrussmote, train_accuracy_xgbrussmote, train_f1_macro_xgbrussmote, test_accuracy_xgbrussmote, test_f1_macro_xgbrussmote = avg_score(model=xgb, X=X_resampled, y=y_resampled, df_test=df_test, smote= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42be0fa",
   "metadata": {},
   "source": [
    "### XGB with SMOTE, RandomUnderSampler and HDBSCAN\n",
    "As the model in the previous notebook showed better results with HDBSCAN we try this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8097f57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the original class distribution\n",
    "print(\"Original class distribution:\", Counter(y))\n",
    "\n",
    "# Apply RandomUnderSampler to reduce the size of majority classes\n",
    "under_sampler = RandomUnderSampler(sampling_strategy={1: 150000, 3: 40000, 2: 40000, 4: 30000, 0: 8000, 5: 4207, 7: 466, 6: 97}, random_state=42)\n",
    "\n",
    "# Fit the undersampling model to the data\n",
    "X_resampled, y_resampled = under_sampler.fit_resample(X, y)\n",
    "\n",
    "# Check the class distribution after undersampling\n",
    "print(\"Distribution after undersampling:\", Counter(y_resampled))\n",
    "\n",
    "# Run the model\n",
    "y_pred_test_xgbrussmotehdbscan, train_accuracy_xgbrussmotehdbscan, train_f1_macro_xgbrussmotehdbscan, test_accuracy_xgbrussmotehdbscan, test_f1_macro_xgbrussmotehdbscan = avg_score(model=xgb, X=X_resampled, y=y_resampled, df_test=df_test, smote= True, hdbscan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c183f94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model results for different class imbalance techniques\n",
    "model_results = {\n",
    "    'Model with Technique': [\n",
    "        'XGB', \n",
    "        'XGB + RUS', \n",
    "        'XGB + RUS + SMOTE', \n",
    "        'XGB + RUS + SMOTE + HDBSCAN'\n",
    "    ],\n",
    "    'Train Accuracy': [\n",
    "        train_accuracy_xgb, \n",
    "        train_accuracy_xgbrus, \n",
    "        train_accuracy_xgbrussmote, \n",
    "        train_accuracy_xgbrussmotehdbscan\n",
    "    ],\n",
    "    'Test Accuracy': [\n",
    "        test_accuracy_xgb, \n",
    "        test_accuracy_xgbrus, \n",
    "        test_accuracy_xgbrussmote, \n",
    "        test_accuracy_xgbrussmotehdbscan\n",
    "    ],\n",
    "    'Train F1 Score': [\n",
    "        train_f1_macro_xgb, \n",
    "        train_f1_macro_xgbrus, \n",
    "        train_f1_macro_xgbrussmote, \n",
    "        train_f1_macro_xgbrussmotehdbscan\n",
    "    ],\n",
    "    'Test F1 Score': [\n",
    "        test_f1_macro_xgb, \n",
    "        test_f1_macro_xgbrus, \n",
    "        test_f1_macro_xgbrussmote, \n",
    "        test_f1_macro_xgbrussmotehdbscan\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create DataFrame with the results\n",
    "results_models = pd.DataFrame(model_results)\n",
    "\n",
    "# Set 'Model with Technique' as the index\n",
    "results_models.set_index('Model with Technique', inplace=True)\n",
    "\n",
    "# Display the DataFrame with results\n",
    "results_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949825ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model names from the 'results_models' DataFrame\n",
    "model_names = results_models.index\n",
    "\n",
    "# Accuracy and F1 scores from the results DataFrame\n",
    "train_accuracy = results_models['Train Accuracy']\n",
    "test_accuracy = results_models['Test Accuracy']\n",
    "train_f1 = results_models['Train F1 Score']\n",
    "test_f1 = results_models['Test F1 Score']\n",
    "\n",
    "# Bar width\n",
    "bar_width = 0.3\n",
    "index = np.arange(len(model_names))\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot bars for Train Accuracy, Test Accuracy, Train F1 Score, and Test F1 Score\n",
    "bar_tra = ax.bar(index - bar_width / 2, train_accuracy, bar_width, label='Train Accuracy', color='#1F77B4' )\n",
    "bar_ta = ax.bar(index - bar_width / 2, test_accuracy, bar_width, label='Test Accuracy', color='#AEC7E8')\n",
    "\n",
    "bar_trf = ax.bar(index + bar_width / 2, train_f1, bar_width, label='Train F1 Score', alpha=0.7, color= '#2CA02C' )\n",
    "bar_tf = ax.bar(index + bar_width / 2, test_f1, bar_width, label='Test F1 Score', alpha=0.7, color='#98DF8A')\n",
    "\n",
    "# Labeling the plot\n",
    "ax.set_ylabel('Scores', fontsize=12)\n",
    "ax.set_title('Comparison of Model Performance (Accuracy & F1 Score)', fontsize=14)\n",
    "\n",
    "# Set the model names on the x-axis from 'results_models' index\n",
    "ax.set_xticks(index)\n",
    "ax.set_xticklabels(model_names)\n",
    "\n",
    "# Display the legend\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot with tight layout to ensure no labels are cut off\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4e6835",
   "metadata": {},
   "source": [
    "To store the results in an excel spreadsheet.    \n",
    "The model chosen as the best is 'XGB with RandomUnderSampler' as it presents a high f1 score and lower overfitting in comparison to the other models tried in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94efbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = target_le.inverse_transform(list(y_pred_test_xgbrus))\n",
    "\n",
    "# Prepare the DataFrame for submission\n",
    "ids = pd.DataFrame(df_test.index)  # Extract IDs from the test set\n",
    "predict_df = pd.DataFrame(predict, columns=['Claim Injury Type'])\n",
    "\n",
    "# Combine IDs and predictions for final submission\n",
    "final = pd.concat([ids, predict_df], axis=1)\n",
    "\n",
    "# Reset index and save to CSV\n",
    "final.reset_index(drop=True, inplace=True)\n",
    "final.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
